{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7cAgChVUwds"
      },
      "source": [
        "# Parte 1: DCCasas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oTO5ytHCUwdv"
      },
      "source": [
        "Nota de los ayudantes: Por motivos de desempeño de las redes neuronales, recomendamos realizar esta tarea en Google Colab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M-yem7k6Uwdv"
      },
      "source": [
        "### Importando los datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kMokEfMbUwdv"
      },
      "outputs": [],
      "source": [
        "# Importamos las librerías necesarias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use(\"ggplot\")\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, Input, Embedding, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from datetime import datetime\n",
        "from scipy.sparse import csr_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ltyCRhhqUwdw"
      },
      "outputs": [],
      "source": [
        "# Creamos una semilla para que los resultados sean replicables\n",
        "n_alumno = 23103435\n",
        "np.random.seed(n_alumno)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mediante las siguientes líneas podrás descargar la base de datos en la carpeta multimodal_house_prices/ si utilizas google colab, en caso contrario descárgala directamente desde el link\n",
        "!gdown https://drive.google.com/uc?id=1078WtQHBTCe5amlDtfu3bgPbO9PFd31R\n",
        "!unzip --qq multimodal_house_prices.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rsPVftSHUwdw"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>image_id</th>\n",
              "      <th>street</th>\n",
              "      <th>city</th>\n",
              "      <th>bedrooms</th>\n",
              "      <th>bathrooms</th>\n",
              "      <th>sqft</th>\n",
              "      <th>price</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>124 C Street W</td>\n",
              "      <td>Brawley, CA</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>713</td>\n",
              "      <td>228500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>2207 R Carrillo Court</td>\n",
              "      <td>Calexico, CA</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2547</td>\n",
              "      <td>385100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "      <td>1100 CAMILIA Street</td>\n",
              "      <td>Calexico, CA</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2769</td>\n",
              "      <td>415000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7</td>\n",
              "      <td>803 Chaparral Court</td>\n",
              "      <td>Brawley, CA</td>\n",
              "      <td>5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2600</td>\n",
              "      <td>545000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>8</td>\n",
              "      <td>803 Chaparral Court</td>\n",
              "      <td>Brawley, CA</td>\n",
              "      <td>5</td>\n",
              "      <td>2.1</td>\n",
              "      <td>2600</td>\n",
              "      <td>545000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   image_id                 street          city  bedrooms  bathrooms  sqft  \\\n",
              "0         1         124 C Street W   Brawley, CA         3        2.0   713   \n",
              "1         4  2207 R Carrillo Court  Calexico, CA         4        3.0  2547   \n",
              "2         6    1100 CAMILIA Street  Calexico, CA         4        3.0  2769   \n",
              "3         7    803 Chaparral Court   Brawley, CA         5        2.1  2600   \n",
              "4         8    803 Chaparral Court   Brawley, CA         5        2.1  2600   \n",
              "\n",
              "    price  \n",
              "0  228500  \n",
              "1  385100  \n",
              "2  415000  \n",
              "3  545000  \n",
              "4  545000  "
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#path = '/multimodal_house_prices/'   # Si corres el notebook a nivel local\n",
        "path = 'multimodal_house_prices/'   # Si corres el notebook en google colab\n",
        "\n",
        "# Importamos el csv\n",
        "meta_data = pd.read_csv(path + \"data.csv\")\n",
        "\n",
        "# Veamos las primeras 5 observaciones\n",
        "meta_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uCLsETV_Uwdx"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "12518it [00:39, 314.75it/s]\n"
          ]
        }
      ],
      "source": [
        "# Preparación de datos para el MLP\n",
        "X_mlp = meta_data.drop(['price', 'image_id'], axis=1)\n",
        "\n",
        "# Definir la variable objetivo\n",
        "y = np.array(meta_data[\"price\"].tolist())\n",
        "\n",
        "# Función para extraer características de una imagen\n",
        "def image_processing(file):\n",
        "    image = cv2.imread(file)\n",
        "\n",
        "    # Obtén las dimensiones de la imagen\n",
        "    height, width = image.shape[:2]\n",
        "\n",
        "    # Verifica si la imagen ya tiene las dimensiones deseadas\n",
        "    if height == 311 and width == 415:\n",
        "        return image\n",
        "    else:\n",
        "        # Redimensiona la imagen a 415x311 con interpolación lineal\n",
        "        resized_image = cv2.resize(image, (415, 311), interpolation=cv2.INTER_LINEAR)\n",
        "        return resized_image\n",
        "    return image\n",
        "\n",
        "# Lista vacía para guardar los datos procesados\n",
        "extracted_cnn = []\n",
        "\n",
        "# Iterar sobre cada fila del DataFrame\n",
        "for index_num, row in tqdm(meta_data.iterrows()):\n",
        "    # Obtener el path de la imagen\n",
        "    file_name = os.path.join(os.path.abspath(path), 'images/' +  str(row['image_id']) + '.jpg')\n",
        "\n",
        "    # Obtener el valor objetivo (por ejemplo, el precio)\n",
        "    target_value = row['price']\n",
        "\n",
        "    # Usar la función definida arriba para procesar la imagen\n",
        "    data = image_processing(file_name)\n",
        "\n",
        "    # Guardar la imagen redimensionada\n",
        "    extracted_cnn.append(data)\n",
        "\n",
        "# Definir los datos para la CNN\n",
        "X_cnn = np.array(extracted_cnn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVjXRfRxUwdx"
      },
      "source": [
        "### Actividad 1: Importando y comprendiendo los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGgYkav_Uwdx"
      },
      "source": [
        "* Investiga y describe por qué el preprocesamiento es una etapa crucial para las redes neuronales. Explica cómo los pasos de preprocesamiento pueden afectar el rendimiento de un modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoZdYj2zUwdx"
      },
      "source": [
        "\\\\\n",
        "\n",
        "El preprocesamiento consiste básicamente en limpiar la data; organizarla, volverla numérica y homogénea y quitar la data ruidosa, lo cual permite que la red pueda procesar los datos y encontrar patrones de forma efectiva. Es decir, hacer que los datos a procesar sean de la mejor calidad posible, de tal forma que el modelo pueda predecir correctamente y no lo haga a partir de ruido. Por ejemplo, algo común es que hayan valores perdidos, los cuales podremos excluir o rellenar, o si tenemos 2 tipos de datos de texto (como \"positivo\" y \"negativo\"), los volvemos 0 o 1.\n",
        "\n",
        "Ahora, hay que tener cuidado con estos pasos, pues de vez en cuando pueden llevar a sesgo, por ejemplo, si se suaviza demasiado una data, podría ocurrir que ciertos features espaciales sean atenuados o derechamente no sean de utilidad, ya que se homogeneizó el espacio.\n",
        "\n",
        "Por otro lado, eliminar el ruido evita la generación de features que realmente no tenían ningún significado, y evita así que el modelo les tome importancia.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de https://www.sciencedirect.com/science/article/pii/B9780128144824000024?fr=RR-2&ref=pdf_download&rr=8326537df84ed76e\n",
        "\n",
        "https://www.sciencedirect.com/science/article/pii/B9780128212295000033?ref=pdf_download&fr=RR-2&rr=832654c13f7bd746"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6K4O-hZwUwdx"
      },
      "source": [
        "* Si tuviéramos pocas imágenes para entrenar un modelo, ¿qué técnicas podrías usar para enriquecer el conjunto de datos? Investiga sobre el aumento de datos en imágenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48_n2utFUwdx"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Una técnica es el aumento de data, donde por lo general, se modifican ligeramente las imágenes ya existentes en el dataset y se incluyen como nueva data. Estos cambios suelen ser rotaciones, cambios de tamaño, zoom, cambios de colores, o de contrastes o brillo, o incluso borrar pequeñas partes de la imagen original, de tal forma que la información siga siendo de utilidad para el modelo, pero genere nueva información en vez de hacer que el programa solo memorice. Se debe hacer una verificación de la imagen luego de las modificaciones para asegurarse de no haber modificado demasiado estas para no ser de utilidad para lo que queremos.\n",
        "\n",
        "Otra forma de generar nueva data es usar imágenes sintéticas generadas por otras inteligencias artificiales.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de https://www.datacamp.com/tutorial/complete-guide-data-augmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyiFnWTBUwdx"
      },
      "source": [
        "### Actividad 2: Explorando los Multilayer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccjYq2qkUwdx"
      },
      "source": [
        "* Discute cómo la profundidad y el ancho (número de capas y neuronas por capa) de un MLP afectan su capacidad para aprender patrones complejos. ¿Cuáles son los desafíos relacionados con el aumento de la complejidad del modelo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d73iSTucUwdy"
      },
      "source": [
        "\\\\\n",
        "\n",
        "La profundidad y el ancho modelan la complejidad del modelo, su rendimiento y capacidad de aprendizaje.\n",
        "\n",
        "La profundidad del MLP es la que modela representaciones más complejas de los datos, y mientras más profundas, más complejas. Esto es similar a lo visto en clases con los random forest, y tal como en este caso, si la red es demasiado profunda, podríamos llegar a un sobreajuste. Por otro lado, entrenar redes muy profundas puede ser costoso y requerir mucho tiempo de cómputo.\n",
        "\n",
        "Otra cosa a notar es que los errores se van propagando por las capas, pero se reducen exponencialmente junto a estas, sin embargo esto a su vez impide que se realice bien el ajuste de pesos backpropagation, por lo que hay que tener cuidado aquí también.\n",
        "\n",
        "El ancho de la red como es imaginable, modela la capacidad de aprendizaje del modelo sobre los patrones de los datos para poder clasificarlos, ya que mientras más neuronas, más patrones se podrán capturar, por tanto redes anchas pueden adaptarse mejor a relaciones más complejas.\n",
        "\n",
        "Al igual que antes, redes más anchas pueden llevar a más sobreajuste si los datos son muy pocos, y demoran más tiempo de cómputo tanto en el entrenamiento como en el testeo y validación. Por tanto debemos tener un buen balance a la hora de decidir el ancho y la profundidad del MLP.\n",
        "\n",
        "Entnonces, la profundidad y ancho que elijamos dependerá de cuán complejas sean las relaciones de nuestros datos, no siempre necesitaremos mucha complejidad.\n",
        "\n",
        "\\\\ \n",
        "\n",
        "de https://www.v7labs.com/blog/data-augmentation-guide \n",
        "https://medium.com/@guillaumelbr13/what-is-a-wide-deep-learning-model-b12dd469f891#:~:text=To%20understand%20the%20use%20of,model%20is%20used%20for%20generalization. \n",
        "\n",
        "https://colah.github.io/posts/2014-03-NN-Manifolds-Topology/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O08-EHcSUwdy"
      },
      "source": [
        "* Investiga y compara al menos dos funciones de activación no lineales diferentes utilizadas en MLPs. ¿Cómo afectan estas funciones al tipo de decisiones que puede aprender la red? Considera aspectos como la saturación y la no linealidad."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDUL-v1JUwdy"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Una función de activación en una red neuronal define cómo la suma de los inputs se transforma al output. La elección de estas tendrá un gran impacto en el funcionamiento de la red. En general, están las lineales y las no lineales, y dentro de este grupo tendremos varias funciones que suelen ser ocupadas con mayor frecuencia, por ejemplo:\n",
        "\n",
        "- Relu: Esta se usa bastante hoy en día, significa Rectified Linear Unit. Es bastante eficiente computacionalmente, esto porque solo activa algunas neuronas y no todas. Otra ventaja es que permite el uso de backpropagation de forma muy eficiente para llegar al mínimo, ya que la forma de la curva es lineal desde cierto punto, permitiendo que converja a un mínimo global. En general no se satura, ya que la derivada nunca se hace 0 en la zona lineal. Esta tiene la forma de:\n",
        "\n",
        "$$ f(x) = max(0, x) $$\n",
        "\n",
        "Por tanto, su rango va de 0 a infinito. Sin embargo, como cierta parte de la función cae a una línea horizontal en 0, el gradiente igual, por tanto los pesos de ciertas neuronas no se actualizarán y por tanto estas no se activan y no serán de utilidad. Este problema se llama \"Dying Relu problem\", aunqeu en algunos casos esto podría ser útil, pero en caso contrario, se puede usar \"Leaky ReLu\", función que soluciona este problema.\n",
        "\n",
        "- Sigmoide: También conocida como la función logística. Sus valores van de 0 a 1, por tanto se puede interpretar como una probabilidad, por tanto valores muy bajos van a 0 y valores muy altos a 1. Pese a ser buena para clasificar, tiene un gran problema, y es que satura y mata a los gradientes, y el output no está centrado en 0, por lo que el gradiente, pese a ser \"suave\" debe ir en direcciones distintas, haciendo que la red no pueda seguir aprendiendo o lo haga de forma muy lenta. El gradiente vemos que tiene puntos donde muere, pues tiene la forma de:\n",
        "\n",
        "$$ f'(x) = sigmoid(x)*(1-sigmoid(x)) $$\n",
        "\n",
        "\n",
        "Entre estas dos funciones, ReLu es más eficiente y resuelve el problema del \"vanishing gradient\", que fue lo explicado en el párrafo anterior, pero sigue teniendo sus propios problemas.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de: https://bootcampai.medium.com/redes-neuronales-13349dd1a5bb\n",
        "https://telefonicatech.com/blog/las-matematicas-del-machine-learning-funciones-de-activacion\n",
        "https://www.kdnuggets.com/2022/06/activation-functions-work-deep-learning.html#:~:text=Binary%20Step%20Activation%20Function&text=The%20activation%20function%20compares%20the,the%20next%20or%20hidden%20layer.\n",
        "https://machinelearningmastery.com/choose-an-activation-function-for-deep-learning/ \n",
        "https://www.v7labs.com/blog/neural-networks-activation-functions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxjHZH2sUwdy"
      },
      "source": [
        "* Examina las causas y síntomas del overfitting en MLP. ¿Qué técnicas se pueden aplicar para prevenir este problema y cómo afectan el proceso de aprendizaje?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKKyeeHFUwdy"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Como vimos en clases, el overfitting se produce cuando el modelo se entrena con muchos datos, tal que comienza a aprender de datos defectuosos o ruidosos o memoriza la información y ya no es capaz de generalizar.\n",
        "\n",
        "Una solución es utilizar algoritmos lineales, pues es un modelo realista para datos lineales, pero esto está claramente limitado para ciertos datos posibles.\n",
        "\n",
        "Otra idea es analizar la validación del set de datos para ir controlando el bias y la varianza, y que este conjunto tenga datos muy variados, e ir cambiando las condiciones para que el modelo prediga lo mejor posible en este set, y que los datos de entrenamiento estén balanceados. Se puede ocupar validación cruzada, la cual evalúa de forma robusta el rendimiento. Esto funcionaría bastante bien para mejorar la varianza.\n",
        "\n",
        "A veces conviene prevenir una cantidad excesiva de features que no tengan tanto muestreo, seleccionando las más importantes o dándoles más peso, o incorporar más datos de estas clases submuestreadas. Se pueden añadir términos de regularización, los cuales penalizan los coeficientes grandes para ajustar el modelo, lo que permitirá que el modelo aprenda más de estas clases.\n",
        "\n",
        "También reducir la profundidad del modelo, como vimos en clases, es de utilidad, pero teniendo en consideración que esto podría reducir la complejidad del aprendizaje del modelo.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de: https://protecciondatos-lopd.com/empresas/overfitting/ \n",
        "https://telefonicatech.com/blog/que-es-overfitting-y-como-evitarlo-html-2 \n",
        "https://machinelearningparatodos.com/que-es-el-sobreajuste-u-overfitting-y-por-que-debemos-evitarlo/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LtOC5rrGUwdy"
      },
      "source": [
        "* Más allá del SGD (Stochastic Gradient Descent) y Adam, investiga sobre otro método de optimización utilizado en el entrenamiento de MLP. ¿Cuáles son sus características únicas y en qué situaciones podría ser preferible?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cof3uL6iUwdy"
      },
      "source": [
        "Un problema de optimización, como ya sabemos, consiste en maximizar o minimizar una función según sea necesario. En este caso, queremos minimizar la función de coste asociada ak modelo. Uno de estos modelos es Eve:\n",
        "\n",
        "Es una modificación a Adam basado en Adagrad, que agrega coeficientes que capturan ciertas propiedades de la función objetivo. Es útil para clasificar imágenes o para redes de lenguaje, y funciona con deep neural networks también.\n",
        "\n",
        "El learning rate es bajo, para evitar divergencias, pero va variando. Primero se introduce un coeficiente escalar dt para ir adaptando el learning rate inicial, tal que:\n",
        "\n",
        "$$ \\alpha_{t} = \\frac{\\alpha_{1}}{dt} $$\n",
        "\n",
        "variaciones altas en dt entonces bajarán el learning rate. Entonces, hacemos el valor:\n",
        "\n",
        "$$ dt = |f_{t} - f_{t-1}| $$\n",
        "\n",
        "\n",
        "el cual captura la variación de la función f en un tiempo t a un tiempo t+1. Vemos que si la variación es larga, entonces el peso $\\alpha_{t}$ será menor. Entonces, esto nos permite que lejos del mínimo demos pasos más largos, y cerca del mínimo demos pasos más cortos hasta llegar al valor correcto de forma simple y, según aseguran sus creadores, computacionalmente eficiente para grandes CNN. Aseguran también haberlo comparado con otros métodos y haber obtenido resultados similares o mejores a otros métodos populares, incluyendo Adam.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de: https://diposit.ub.edu/dspace/bitstream/2445/176952/2/176952.pdf \n",
        "https://arxiv.org/pdf/1611.01505.pdf "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ErZH-VjGUwdy"
      },
      "source": [
        "* Identifica y analiza un estudio de caso donde se haya utilizado un MLP para resolver un problema real. ¿Qué características del problema hicieron que un MLP fuera una buena elección y cómo se diseñó la arquitectura de la red para adaptarse a las necesidades específicas del problema?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bygCiS5QUwdz"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Hace poco hubo un estudio en Valparaíso sobre qué tan bien funcionaba la parcelación de cerebros del proyecto \"Human Connectome Proyect\" (HCP), el cual tiene una base de datos de imágenes de resonancia magnética (MRI) de cerebros, para ver si su algoritmo segmentaba bien las zonas del cerebro y funcionaba en operaciones de gliomas (un tipo de tumor) cerebrales. \n",
        "\n",
        "Esta segmentación no había sido testeada de antemano de forma clínica, y para esto testearon a 40 pacientes con gliomas, y para realizar la planificación de la extracción del tumor, se utilizó esta representación del cerebro, mientras los pacientes realizaban tareas del lenguaje y motoras, de forma de asegurarse de no afectar estas áreas del cerebro tras la cirugía. Se testearon los resultados y se operaron a los pacientes mientras estaban despiertos y se obtuvieron buenos resultados para ambas áreas.\n",
        "\n",
        "La parcelación HCP automatizada se realiza a través de un modelo de machine learning capaz de reconocer las distintas áreas en una gran variedad de cerebros. Se separaron tres grupos, entrenamiento, testeo, y un pequeño grupo de validación de pacientes que compartían lazos sanguíneos con personas del grupo de entrenamiento.\n",
        "\n",
        "Se pre-procesaron las imágenes y luego se extrajeron los features.\n",
        "\n",
        "Se realizaron estos features midiendo la conectividad entre funcional entre distintos voxels del cerebro (es decir, se midió qué tan parecida era la actividad entre distintos puntos del cerebro) usando la correlación de Pearson. Se agruparon los features entre los que se hicieron con los sujetos en reposo, realizando alguna actividad, el grosos cortical, etc.\n",
        "\n",
        "Se utilizó un clasificador supervisado para delinear las zonas del cerebro, a partir de imágenes delineadas por expertos en neuroanatomía, y así delimitar 180 zonas por hemisferio a partir de esto. \n",
        "\n",
        "Se utilizó un multilayer perceptron para generar outputs de 0 a 1 de qué tan posible es que cierta delimitación sea parte de un área que se esté clasificando dado las zonas que tiene alrededor y su activación, y se utilizó un \"sensitivity metric\" para clasificar, la cual era la derivada parcial de cada feature de cada área multiplicado por la magnitud del gradiente de ese feature.\n",
        "\n",
        "Se utilizó cross-validation, y se ocuparon imágenes de un mismo sujeto, pero en una sesión MRI distinta para comprobar los resultados.\n",
        "\n",
        "\n",
        "\\\\\n",
        "\n",
        "de: https://pubmed.ncbi.nlm.nih.gov/36455268/ \n",
        "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4990127/ "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMHn8RiUUwdz"
      },
      "source": [
        "### Implementación de un Multilayer Perceptron (MLP)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcwnO8QmUwdz"
      },
      "source": [
        "* Implementa un MLP con al menos dos capas ocultas. Entrena tu modelo en el conjunto de datos de entrenamiento y realiza ajustes en los hiperparámetros (como la tasa de aprendizaje, número de neuronas, funciones de activación) para mejorar el rendimiento del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {},
      "outputs": [],
      "source": [
        "# primero, vemos que la data no está en el formato que necesitamos\n",
        "# para ser procesados, por tanto debemos convertirlos a valores numéricos:\n",
        "# vemos que debemos convertir \"street\" y \"city\".\n",
        "# de: https://machinelearninggeek.com/multi-layer-perceptron-neural-network-using-python/\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "X_mlp['street'] = le.fit_transform(X_mlp['street'])\n",
        "X_mlp['city'] = le.fit_transform(X_mlp['city'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "       street  city  bedrooms  bathrooms  sqft\n",
            "0         992    47         3        2.0   713\n",
            "1        3652    54         4        3.0  2547\n",
            "2         395    54         4        3.0  2769\n",
            "3        9246    47         5        2.1  2600\n",
            "4        9246    47         5        2.1  2600\n",
            "...       ...   ...       ...        ...   ...\n",
            "12513    3896   378         3        3.0  1677\n",
            "12514    3330   253         5        3.1  4457\n",
            "12515    6601   220         5        4.1  4092\n",
            "12516    6833   361         5        3.0  2773\n",
            "12517    5891   245         4        2.0  2086\n",
            "\n",
            "[12518 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "# Vemos ahora que esto funcionó:\n",
        "\n",
        "print(X_mlp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "hHCRziArUwdz"
      },
      "outputs": [],
      "source": [
        "# normalizamos nuestra data para que el gradiente funcione bien:\n",
        "sc = StandardScaler()\n",
        "X = sc.fit_transform(X_mlp)\n",
        "\n",
        "# creamos con esto test de entrenamiento, test y validación:\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
        "\n",
        "# como el dataset es grande, decidí tener porcentajes bajos de test y de validation, pero quise que fuese un poco mayor\n",
        "# el de validation para comprobar antes que no hubiese nada extraño.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 2s 4ms/step - loss: 600652185600.0000 - mae: 684152.7500 - val_loss: 584482357248.0000 - val_mae: 675995.3750\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 555145887744.0000 - mae: 652936.7500 - val_loss: 468495892480.0000 - val_mae: 593955.7500\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 346111770624.0000 - mae: 482008.0938 - val_loss: 207465463808.0000 - val_mae: 343367.6875\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 166540591104.0000 - mae: 300297.1562 - val_loss: 139098832896.0000 - val_mae: 259102.7969\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 136011235328.0000 - mae: 268069.9688 - val_loss: 126049476608.0000 - val_mae: 244498.9375\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 124164579328.0000 - mae: 255879.6562 - val_loss: 116514922496.0000 - val_mae: 234793.2031\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 116764319744.0000 - mae: 248165.9688 - val_loss: 109017563136.0000 - val_mae: 228357.0312\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 113081245696.0000 - mae: 243728.8438 - val_loss: 103537524736.0000 - val_mae: 224228.7031\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 106697736192.0000 - mae: 238907.4531 - val_loss: 99516907520.0000 - val_mae: 221146.8438\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 106870407168.0000 - mae: 238485.2812 - val_loss: 96717840384.0000 - val_mae: 219977.3281\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 105124732928.0000 - mae: 235945.5312 - val_loss: 94511292416.0000 - val_mae: 218268.6719\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 102719225856.0000 - mae: 234509.6719 - val_loss: 92932276224.0000 - val_mae: 217418.5781\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 101568258048.0000 - mae: 234094.3594 - val_loss: 91932975104.0000 - val_mae: 218308.0938\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 101443256320.0000 - mae: 234038.5469 - val_loss: 90582638592.0000 - val_mae: 217315.1719\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 101695062016.0000 - mae: 234125.7500 - val_loss: 89720233984.0000 - val_mae: 217731.0938\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 100428726272.0000 - mae: 233390.8125 - val_loss: 88950243328.0000 - val_mae: 216200.5312\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 98024890368.0000 - mae: 230786.7500 - val_loss: 88386314240.0000 - val_mae: 215813.1094\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99147694080.0000 - mae: 231825.6875 - val_loss: 87818952704.0000 - val_mae: 215961.4375\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99018604544.0000 - mae: 230664.0156 - val_loss: 87474618368.0000 - val_mae: 215111.2812\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99573719040.0000 - mae: 230523.9844 - val_loss: 87026638848.0000 - val_mae: 215594.6562\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 98959482880.0000 - mae: 231832.5312 - val_loss: 86613704704.0000 - val_mae: 215411.4688\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 98910732288.0000 - mae: 232063.5625 - val_loss: 86397452288.0000 - val_mae: 214506.7344\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99447029760.0000 - mae: 231247.7656 - val_loss: 86146973696.0000 - val_mae: 215039.8906\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99125911552.0000 - mae: 230816.6875 - val_loss: 86125486080.0000 - val_mae: 216684.1719\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99887611904.0000 - mae: 232434.2344 - val_loss: 85794357248.0000 - val_mae: 215106.9062\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 98948874240.0000 - mae: 230979.7031 - val_loss: 85608660992.0000 - val_mae: 215352.2031\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99522437120.0000 - mae: 232394.8281 - val_loss: 85571903488.0000 - val_mae: 214308.0000\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 98901311488.0000 - mae: 230923.1094 - val_loss: 85491744768.0000 - val_mae: 214501.7812\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 98351243264.0000 - mae: 231513.1875 - val_loss: 85376548864.0000 - val_mae: 215309.4219\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99128090624.0000 - mae: 232552.8750 - val_loss: 85298626560.0000 - val_mae: 215092.2969\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 97121394688.0000 - mae: 230467.7969 - val_loss: 85203935232.0000 - val_mae: 215415.4375\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 99254034432.0000 - mae: 232434.7812 - val_loss: 85022244864.0000 - val_mae: 214468.8281\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 97990615040.0000 - mae: 230458.8750 - val_loss: 84900028416.0000 - val_mae: 214444.1094\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 98428067840.0000 - mae: 231722.5938 - val_loss: 84724482048.0000 - val_mae: 214620.7031\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 98645467136.0000 - mae: 231809.9219 - val_loss: 84721475584.0000 - val_mae: 214859.8281\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 97930862592.0000 - mae: 230743.4844 - val_loss: 84633034752.0000 - val_mae: 214964.3906\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 98162966528.0000 - mae: 231636.7656 - val_loss: 84511719424.0000 - val_mae: 214215.7188\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 98768437248.0000 - mae: 231663.2969 - val_loss: 84522254336.0000 - val_mae: 214271.3594\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 96819003392.0000 - mae: 230311.9844 - val_loss: 84388069376.0000 - val_mae: 214429.0312\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 98701017088.0000 - mae: 231852.4062 - val_loss: 84360806400.0000 - val_mae: 213657.6562\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 97128480768.0000 - mae: 230204.7656 - val_loss: 84276756480.0000 - val_mae: 214848.0000\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 98159902720.0000 - mae: 231233.6250 - val_loss: 84330831872.0000 - val_mae: 215207.8750\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 97717592064.0000 - mae: 230860.9062 - val_loss: 84238123008.0000 - val_mae: 214912.4375\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 98347982848.0000 - mae: 231083.5781 - val_loss: 84265984000.0000 - val_mae: 214989.9062\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99119775744.0000 - mae: 231987.9844 - val_loss: 84246749184.0000 - val_mae: 214411.8594\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 98940297216.0000 - mae: 232271.1250 - val_loss: 84208410624.0000 - val_mae: 214354.7188\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 98574778368.0000 - mae: 230609.5625 - val_loss: 84109246464.0000 - val_mae: 214229.1250\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 99258081280.0000 - mae: 231410.6406 - val_loss: 83988094976.0000 - val_mae: 213772.1250\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 98920636416.0000 - mae: 230621.0312 - val_loss: 84009680896.0000 - val_mae: 213841.4375\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 96361267200.0000 - mae: 229678.2500 - val_loss: 84087529472.0000 - val_mae: 213542.0781\n"
          ]
        }
      ],
      "source": [
        "# de: https://www.tensorflow.org/api_docs/python/tf/keras/Sequential\n",
        "# https://www.projectpro.io/recipes/what-is-batch-normalization-keras\n",
        "\n",
        "model = Sequential()\n",
        "# capa inicial:\n",
        "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "\n",
        "# capas ocultas:\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "# capa de salida:\n",
        "model.add(Dense(1, activation='linear'))\n",
        "\n",
        "# añadimos el optimizador y la función de pérdida:\n",
        "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# fiteamos el modelo:\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-_SlLZPUwdz"
      },
      "source": [
        "* Evalúa el rendimiento de tu modelo en el conjunto de datos de prueba. Utiliza métricas relevantes para problemas de regresión, como el error cuadrático medio (MSE)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "62/79 [======================>.......] - ETA: 0s - loss: 90385113088.0000 - mae: 223042.0312"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 3ms/step - loss: 89004089344.0000 - mae: 220271.1094\n",
            "Mean Absolute Error on Test Set: 220271.109375\n",
            "Mean Squared Error on Test Set: 89004089344.0\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos:\n",
        "loss, mae = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Absolute Error on Test Set: {mae}')\n",
        "print(f'Mean Squared Error on Test Set: {loss}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 1ms/step\n",
            "R^2 Score on Validation Set: 0.3434336823282381\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "R^2 Score on Test Set: 0.36795647997000736\n"
          ]
        }
      ],
      "source": [
        "# de: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.r2_score.html\n",
        "\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "# No podemos usar accuracy_score, pero podemos usar métricas de regresión como:\n",
        "y_predv = model.predict(X_val)\n",
        "r2 = r2_score(y_val, y_predv)\n",
        "print(f'R^2 Score on Validation Set: {r2}')\n",
        "\n",
        "y_predt = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_predt)\n",
        "print(f'R^2 Score on Test Set: {r2}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 label value: 699000 estimated value: [680685.6] diferencia: [2.62008226]\n",
            "2 label value: 599000 estimated value: [526889.4] diferencia: [12.03850167]\n",
            "3 label value: 1325000 estimated value: [1036050.] diferencia: [21.80754717]\n",
            "4 label value: 325000 estimated value: [399783.88] diferencia: [23.01042308]\n",
            "5 label value: 1639000 estimated value: [1716848.9] diferencia: [4.74977883]\n",
            "6 label value: 1475000 estimated value: [859520.5] diferencia: [41.72742373]\n",
            "7 label value: 409000 estimated value: [363880.7] diferencia: [11.03161675]\n",
            "8 label value: 1795000 estimated value: [751137.8] diferencia: [58.15388231]\n",
            "9 label value: 625000 estimated value: [538636.44] diferencia: [13.81817]\n",
            "10 label value: 249000 estimated value: [479071.44] diferencia: [92.39816767]\n",
            "11 label value: 980000 estimated value: [584659.2] diferencia: [40.34089923]\n",
            "12 label value: 399000 estimated value: [476979.4] diferencia: [19.54371084]\n",
            "13 label value: 575500 estimated value: [658870.9] diferencia: [14.48668549]\n",
            "14 label value: 598888 estimated value: [659463.75] diferencia: [10.11470425]\n",
            "15 label value: 731414 estimated value: [554572.1] diferencia: [24.17808177]\n",
            "16 label value: 315000 estimated value: [529963.1] diferencia: [68.2422619]\n",
            "17 label value: 615000 estimated value: [1076088.1] diferencia: [74.97367886]\n",
            "18 label value: 618000 estimated value: [664632.4] diferencia: [7.54569175]\n",
            "19 label value: 305000 estimated value: [441792.44] diferencia: [44.84997951]\n",
            "20 label value: 744000 estimated value: [446768.62] diferencia: [39.95045363]\n",
            "21 label value: 349750 estimated value: [527456.6] diferencia: [50.80961401]\n",
            "22 label value: 699000 estimated value: [830887.44] diferencia: [18.86801681]\n",
            "23 label value: 750000 estimated value: [570148.5] diferencia: [23.9802]\n",
            "24 label value: 650000 estimated value: [476050.28] diferencia: [26.76149519]\n",
            "25 label value: 1800000 estimated value: [822654.44] diferencia: [54.29697569]\n",
            "26 label value: 569900 estimated value: [746383.75] diferencia: [30.9674943]\n",
            "27 label value: 463000 estimated value: [384387.7] diferencia: [16.97890119]\n",
            "28 label value: 485000 estimated value: [707295.6] diferencia: [45.83414948]\n",
            "29 label value: 789000 estimated value: [626998.] diferencia: [20.53257288]\n",
            "30 label value: 1350000 estimated value: [1742096.6] diferencia: [29.04419444]\n",
            "31 label value: 1014900 estimated value: [527691.5] diferencia: [48.00556705]\n",
            "32 label value: 555000 estimated value: [919986.5] diferencia: [65.76333333]\n",
            "33 label value: 579800 estimated value: [660105.5] diferencia: [13.85055191]\n",
            "34 label value: 218000 estimated value: [427918.] diferencia: [96.29266055]\n",
            "35 label value: 599000 estimated value: [532107.9] diferencia: [11.16729967]\n",
            "36 label value: 299000 estimated value: [457041.75] diferencia: [52.85677258]\n",
            "37 label value: 945000 estimated value: [622645.56] diferencia: [34.11158069]\n",
            "38 label value: 899000 estimated value: [937309.25] diferencia: [4.26131813]\n",
            "39 label value: 259000 estimated value: [490338.8] diferencia: [89.32000483]\n",
            "40 label value: 340000 estimated value: [613891.9] diferencia: [80.55643382]\n",
            "41 label value: 888900 estimated value: [926923.4] diferencia: [4.27757622]\n",
            "42 label value: 554900 estimated value: [508379.56] diferencia: [8.38357136]\n",
            "43 label value: 1399900 estimated value: [746010.06] diferencia: [46.70976052]\n",
            "44 label value: 298800 estimated value: [384100.12] diferencia: [28.54756526]\n",
            "45 label value: 249000 estimated value: [549354.56] diferencia: [120.62432229]\n",
            "46 label value: 535000 estimated value: [492489.6] diferencia: [7.94587033]\n",
            "47 label value: 929000 estimated value: [830809.4] diferencia: [10.56949677]\n",
            "48 label value: 510990 estimated value: [610725.25] diferencia: [19.51804341]\n",
            "49 label value: 779900 estimated value: [536327.4] diferencia: [31.23126362]\n",
            "50 label value: 799999 estimated value: [714696.1] diferencia: [10.6628727]\n",
            "51 label value: 498000 estimated value: [480731.] diferencia: [3.46767068]\n",
            "52 label value: 1050000 estimated value: [1365751.6] diferencia: [30.07158333]\n",
            "53 label value: 699000 estimated value: [419003.] diferencia: [40.05679542]\n",
            "54 label value: 850000 estimated value: [492208.25] diferencia: [42.09314706]\n",
            "55 label value: 375000 estimated value: [503105.94] diferencia: [34.16158333]\n",
            "56 label value: 899900 estimated value: [888018.1] diferencia: [1.32035504]\n",
            "57 label value: 515000 estimated value: [421205.75] diferencia: [18.21247573]\n",
            "58 label value: 216500 estimated value: [452553.44] diferencia: [109.03161085]\n",
            "59 label value: 570000 estimated value: [877793.06] diferencia: [53.99878289]\n",
            "60 label value: 299990 estimated value: [434681.06] diferencia: [44.89851745]\n",
            "61 label value: 698000 estimated value: [705999.3] diferencia: [1.14603331]\n",
            "62 label value: 285000 estimated value: [435025.] diferencia: [52.64035088]\n",
            "63 label value: 390000 estimated value: [600614.06] diferencia: [54.00360577]\n",
            "64 label value: 799000 estimated value: [792820.] diferencia: [0.77346683]\n",
            "65 label value: 819000 estimated value: [709713.8] diferencia: [13.34385684]\n",
            "66 label value: 665000 estimated value: [496619.53] diferencia: [25.32037124]\n",
            "67 label value: 425000 estimated value: [862307.5] diferencia: [102.89588235]\n",
            "68 label value: 320000 estimated value: [561242.94] diferencia: [75.38841797]\n",
            "69 label value: 205000 estimated value: [465377.62] diferencia: [127.01347561]\n",
            "70 label value: 389977 estimated value: [573552.4] diferencia: [47.0733851]\n",
            "71 label value: 998800 estimated value: [556945.44] diferencia: [44.2385425]\n",
            "72 label value: 269900 estimated value: [604908.2] diferencia: [124.12307799]\n",
            "73 label value: 499000 estimated value: [463895.12] diferencia: [7.03504509]\n",
            "74 label value: 969000 estimated value: [867614.25] diferencia: [10.4629257]\n",
            "75 label value: 505000 estimated value: [383556.34] diferencia: [24.04824876]\n",
            "76 label value: 555000 estimated value: [919986.5] diferencia: [65.76333333]\n",
            "77 label value: 799888 estimated value: [570150.3] diferencia: [28.72123191]\n",
            "78 label value: 649888 estimated value: [614575.6] diferencia: [5.43360933]\n",
            "79 label value: 899000 estimated value: "
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[800472.1] diferencia: [10.95971913]\n",
            "80 label value: 380000 estimated value: [539342.25] diferencia: [41.93217105]\n",
            "81 label value: 900000 estimated value: [474762.72] diferencia: [47.24858681]\n",
            "82 label value: 299000 estimated value: [621390.3] diferencia: [107.82284699]\n",
            "83 label value: 599000 estimated value: [587805.1] diferencia: [1.86892738]\n",
            "84 label value: 1258888 estimated value: [625919.25] diferencia: [50.27998917]\n",
            "85 label value: 750000 estimated value: [623242.6] diferencia: [16.90098333]\n",
            "86 label value: 649900 estimated value: [646108.75] diferencia: [0.58335898]\n",
            "87 label value: 505000 estimated value: [437460.44] diferencia: [13.37417079]\n",
            "88 label value: 315000 estimated value: [440212.5] diferencia: [39.75]\n",
            "89 label value: 250000 estimated value: [475481.88] diferencia: [90.19275]\n",
            "90 label value: 565000 estimated value: [524687.3] diferencia: [7.13498894]\n",
            "91 label value: 629950 estimated value: [492483.84] diferencia: [21.82175669]\n",
            "92 label value: 1190000 estimated value: [1099570.] diferencia: [7.59915966]\n",
            "93 label value: 285000 estimated value: [472538.1] diferencia: [65.80283991]\n",
            "94 label value: 550000 estimated value: [506676.75] diferencia: [7.87695455]\n",
            "95 label value: 720000 estimated value: [796270.94] diferencia: [10.59318576]\n",
            "96 label value: 739000 estimated value: [1088405.4] diferencia: [47.28083559]\n",
            "97 label value: 319900 estimated value: [697573.56] diferencia: [118.05988199]\n",
            "98 label value: 678900 estimated value: [839497.75] diferencia: [23.65558256]\n",
            "99 label value: 698000 estimated value: [705999.3] diferencia: [1.14603331]\n"
          ]
        }
      ],
      "source": [
        "# analizamos también la diferencia para ver algo más concreto. Vemos que la diferencia es casi siempre un orden menor\n",
        "# al valor correcto.\n",
        "for i in range(1, 100):\n",
        "    print (i ,\"label value:\", y_test[i], \"estimated value:\", y_predt[i], \"diferencia:\", 100*abs(y_test[i] - y_predt[i])/y_test[i])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCDURbHcUwdz"
      },
      "source": [
        "*  Realiza al menos dos experimentos variando la arquitectura del MLP o los hiperparámetros. Describe cómo cada cambio afecta el rendimiento del modelo y discute tus hallazgos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "Ondu1b7tUwdz"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 2s 4ms/step - loss: 601799000064.0000 - mae: 684922.3750 - val_loss: 590883061760.0000 - val_mae: 680302.3125\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601789562880.0000 - mae: 684915.3750 - val_loss: 590874607616.0000 - val_mae: 680296.2500\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601781698560.0000 - mae: 684909.1250 - val_loss: 590866481152.0000 - val_mae: 680290.2500\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601773375488.0000 - mae: 684903.5625 - val_loss: 590858354688.0000 - val_mae: 680284.3125\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601764855808.0000 - mae: 684897.3750 - val_loss: 590850097152.0000 - val_mae: 680278.3125\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601757057024.0000 - mae: 684891.4375 - val_loss: 590842298368.0000 - val_mae: 680272.3750\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601749061632.0000 - mae: 684885.3750 - val_loss: 590834302976.0000 - val_mae: 680266.5000\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601741131776.0000 - mae: 684879.7500 - val_loss: 590826242048.0000 - val_mae: 680260.5625\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601732874240.0000 - mae: 684873.5625 - val_loss: 590817722368.0000 - val_mae: 680254.4375\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601724092416.0000 - mae: 684866.9375 - val_loss: 590809006080.0000 - val_mae: 680248.0000\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601715245056.0000 - mae: 684860.8125 - val_loss: 590800420864.0000 - val_mae: 680241.8125\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601706790912.0000 - mae: 684854.8750 - val_loss: 590792032256.0000 - val_mae: 680235.4375\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601698467840.0000 - mae: 684848.3125 - val_loss: 590783643648.0000 - val_mae: 680229.4375\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601690013696.0000 - mae: 684842.5000 - val_loss: 590775320576.0000 - val_mae: 680223.1250\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601681494016.0000 - mae: 684836.0625 - val_loss: 590767063040.0000 - val_mae: 680217.1875\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601673039872.0000 - mae: 684830.1250 - val_loss: 590758739968.0000 - val_mae: 680211.0000\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601664913408.0000 - mae: 684824.0625 - val_loss: 590750482432.0000 - val_mae: 680204.9375\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601656393728.0000 - mae: 684817.6875 - val_loss: 590742093824.0000 - val_mae: 680198.7500\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601647874048.0000 - mae: 684811.9375 - val_loss: 590732918784.0000 - val_mae: 680192.2500\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601638502400.0000 - mae: 684804.7500 - val_loss: 590723940352.0000 - val_mae: 680185.4375\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601629523968.0000 - mae: 684798.0625 - val_loss: 590715092992.0000 - val_mae: 680179.0000\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601620676608.0000 - mae: 684792.0000 - val_loss: 590706311168.0000 - val_mae: 680172.4375\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601611960320.0000 - mae: 684785.2500 - val_loss: 590697660416.0000 - val_mae: 680166.3125\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601603375104.0000 - mae: 684779.0625 - val_loss: 590688813056.0000 - val_mae: 680159.9375\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601594396672.0000 - mae: 684772.3125 - val_loss: 590680293376.0000 - val_mae: 680153.4375\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601585745920.0000 - mae: 684766.5000 - val_loss: 590671577088.0000 - val_mae: 680147.0625\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601577029632.0000 - mae: 684759.9375 - val_loss: 590663122944.0000 - val_mae: 680140.6875\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601568575488.0000 - mae: 684753.7500 - val_loss: 590654406656.0000 - val_mae: 680134.4375\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601559990272.0000 - mae: 684747.1875 - val_loss: 590645755904.0000 - val_mae: 680128.1875\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601551077376.0000 - mae: 684740.7500 - val_loss: 590637236224.0000 - val_mae: 680121.8750\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601542295552.0000 - mae: 684734.3750 - val_loss: 590628782080.0000 - val_mae: 680115.4375\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601533841408.0000 - mae: 684728.3750 - val_loss: 590620196864.0000 - val_mae: 680109.2500\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601525125120.0000 - mae: 684721.9375 - val_loss: 590611415040.0000 - val_mae: 680102.7500\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601516474368.0000 - mae: 684715.7500 - val_loss: 590602895360.0000 - val_mae: 680096.4375\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601507889152.0000 - mae: 684709.1875 - val_loss: 590594375680.0000 - val_mae: 680090.2500\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601499172864.0000 - mae: 684703.1250 - val_loss: 590585856000.0000 - val_mae: 680084.0625\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601490456576.0000 - mae: 684696.6875 - val_loss: 590577008640.0000 - val_mae: 680077.5625\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601481871360.0000 - mae: 684690.4375 - val_loss: 590568488960.0000 - val_mae: 680071.1875\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601473155072.0000 - mae: 684683.8750 - val_loss: 590560034816.0000 - val_mae: 680064.8750\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601464504320.0000 - mae: 684677.7500 - val_loss: 590551384064.0000 - val_mae: 680058.5625\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601455919104.0000 - mae: 684671.3750 - val_loss: 590542798848.0000 - val_mae: 680052.3750\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601447333888.0000 - mae: 684665.3125 - val_loss: 590534213632.0000 - val_mae: 680046.0625\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 601438486528.0000 - mae: 684658.4375 - val_loss: 590525693952.0000 - val_mae: 680039.7500\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 601429966848.0000 - mae: 684652.2500 - val_loss: 590516977664.0000 - val_mae: 680033.3750\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 601421447168.0000 - mae: 684646.2500 - val_loss: 590508589056.0000 - val_mae: 680027.0000\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601412468736.0000 - mae: 684639.9375 - val_loss: 590499872768.0000 - val_mae: 680020.5625\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 601404014592.0000 - mae: 684633.5000 - val_loss: 590491353088.0000 - val_mae: 680014.3750\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 601395298304.0000 - mae: 684627.2500 - val_loss: 590482767872.0000 - val_mae: 680008.0625\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 601386516480.0000 - mae: 684621.0625 - val_loss: 590473986048.0000 - val_mae: 680001.8125\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 601377996800.0000 - mae: 684614.6875 - val_loss: 590465335296.0000 - val_mae: 679995.3750\n"
          ]
        }
      ],
      "source": [
        "# Cambio 1: función de activación a sigmoide\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Dense(64, input_dim=X_train.shape[1], activation='sigmoid')) # n_neuronas\n",
        "model1.add(Dense(64, activation='sigmoid'))\n",
        "model1.add(Dense(32, activation='sigmoid'))\n",
        "model1.add(Dense(1, activation='linear')) # con add añadimos el n_layers\n",
        "\n",
        "# añadimos el optimizador y la función de pérdida:\n",
        "model1.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# fiteamos el modelo:\n",
        "history = model1.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/79 [..............................] - ETA: 1s - loss: 781661306880.0000 - mae: 773662.5000"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 618892230656.0000 - mae: 691428.0000\n",
            "Mean Absolute Error on Test Set: 691428.0\n",
            "Mean Squared Error on Test Set: 618892230656.0\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "R^2 Score on Validation Set: -3.610430357670202\n",
            "79/79 [==============================] - 0s 2ms/step\n",
            "R^2 Score on Test Set: -3.3949309754425476\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos:\n",
        "loss1, mae1 = model1.evaluate(X_test, y_test)\n",
        "print(f'Mean Absolute Error on Test Set: {mae1}')\n",
        "print(f'Mean Squared Error on Test Set: {loss1}')\n",
        "\n",
        "# No podemos usar accuracy_score, pero podemos usar:\n",
        "y_predv1 = model1.predict(X_val)\n",
        "r2_11 = r2_score(y_val, y_predv1)\n",
        "print(f'R^2 Score on Validation Set: {r2_11}')\n",
        "\n",
        "y_predt1 = model1.predict(X_test)\n",
        "r2_12 = r2_score(y_test, y_predt1)\n",
        "print(f'R^2 Score on Test Set: {r2_12}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 label value: 699000 estimated value: [317.23926] diferencia: [0.99954615]\n",
            "2 label value: 599000 estimated value: [317.23926] diferencia: [0.99947039]\n",
            "3 label value: 1325000 estimated value: [317.23926] diferencia: [0.99976057]\n",
            "4 label value: 325000 estimated value: [317.23926] diferencia: [0.99902388]\n",
            "5 label value: 1639000 estimated value: [317.23926] diferencia: [0.99980644]\n",
            "6 label value: 1475000 estimated value: [317.23926] diferencia: [0.99978492]\n",
            "7 label value: 409000 estimated value: [317.23926] diferencia: [0.99922435]\n",
            "8 label value: 1795000 estimated value: [317.23926] diferencia: [0.99982327]\n",
            "9 label value: 625000 estimated value: [317.23926] diferencia: [0.99949242]\n",
            "10 label value: 249000 estimated value: [317.23926] diferencia: [0.99872595]\n",
            "11 label value: 980000 estimated value: [317.23926] diferencia: [0.99967629]\n",
            "12 label value: 399000 estimated value: [317.23926] diferencia: [0.99920491]\n",
            "13 label value: 575500 estimated value: [317.23926] diferencia: [0.99944876]\n",
            "14 label value: 598888 estimated value: [317.23926] diferencia: [0.99947029]\n",
            "15 label value: 731414 estimated value: [317.23926] diferencia: [0.99956627]\n",
            "16 label value: 315000 estimated value: [317.23926] diferencia: [0.99899289]\n",
            "17 label value: 615000 estimated value: [317.23926] diferencia: [0.99948416]\n",
            "18 label value: 618000 estimated value: [317.23926] diferencia: [0.99948667]\n",
            "19 label value: 305000 estimated value: [317.23926] diferencia: [0.99895987]\n",
            "20 label value: 744000 estimated value: [317.23926] diferencia: [0.9995736]\n",
            "21 label value: 349750 estimated value: [317.23926] diferencia: [0.99909295]\n",
            "22 label value: 699000 estimated value: [317.23926] diferencia: [0.99954615]\n",
            "23 label value: 750000 estimated value: [317.23926] diferencia: [0.99957701]\n",
            "24 label value: 650000 estimated value: [317.23926] diferencia: [0.99951194]\n",
            "25 label value: 1800000 estimated value: [317.23926] diferencia: [0.99982376]\n",
            "26 label value: 569900 estimated value: [317.23926] diferencia: [0.99944334]\n",
            "27 label value: 463000 estimated value: [317.23926] diferencia: [0.99931482]\n",
            "28 label value: 485000 estimated value: [317.23926] diferencia: [0.9993459]\n",
            "29 label value: 789000 estimated value: [317.23926] diferencia: [0.99959792]\n",
            "30 label value: 1350000 estimated value: [317.23926] diferencia: [0.99976501]\n",
            "31 label value: 1014900 estimated value: [317.23926] diferencia: [0.99968742]\n",
            "32 label value: 555000 estimated value: [317.23926] diferencia: [0.9994284]\n",
            "33 label value: 579800 estimated value: [317.23926] diferencia: [0.99945285]\n",
            "34 label value: 218000 estimated value: [317.23926] diferencia: [0.99854477]\n",
            "35 label value: 599000 estimated value: [317.23926] diferencia: [0.99947039]\n",
            "36 label value: 299000 estimated value: [317.23926] diferencia: [0.998939]\n",
            "37 label value: 945000 estimated value: [317.23926] diferencia: [0.9996643]\n",
            "38 label value: 899000 estimated value: [317.23926] diferencia: [0.99964712]\n",
            "39 label value: 259000 estimated value: [317.23926] diferencia: [0.99877514]\n",
            "40 label value: 340000 estimated value: [317.23926] diferencia: [0.99906694]\n",
            "41 label value: 888900 estimated value: [317.23926] diferencia: [0.99964311]\n",
            "42 label value: 554900 estimated value: [317.23926] diferencia: [0.99942829]\n",
            "43 label value: 1399900 estimated value: [317.23926] diferencia: [0.99977338]\n",
            "44 label value: 298800 estimated value: [317.23926] diferencia: [0.99893829]\n",
            "45 label value: 249000 estimated value: [317.23926] diferencia: [0.99872595]\n",
            "46 label value: 535000 estimated value: [317.23926] diferencia: [0.99940703]\n",
            "47 label value: 929000 estimated value: [317.23926] diferencia: [0.99965852]\n",
            "48 label value: 510990 estimated value: [317.23926] diferencia: [0.99937917]\n",
            "49 label value: 779900 estimated value: [317.23926] diferencia: [0.99959323]\n",
            "50 label value: 799999 estimated value:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " [317.23926] diferencia: [0.99960345]\n",
            "51 label value: 498000 estimated value: [317.23926] diferencia: [0.99936297]\n",
            "52 label value: 1050000 estimated value: [317.23926] diferencia: [0.99969787]\n",
            "53 label value: 699000 estimated value: [317.23926] diferencia: [0.99954615]\n",
            "54 label value: 850000 estimated value: [317.23926] diferencia: [0.99962678]\n",
            "55 label value: 375000 estimated value: [317.23926] diferencia: [0.99915403]\n",
            "56 label value: 899900 estimated value: [317.23926] diferencia: [0.99964747]\n",
            "57 label value: 515000 estimated value: [317.23926] diferencia: [0.999384]\n",
            "58 label value: 216500 estimated value: [317.23926] diferencia: [0.99853469]\n",
            "59 label value: 570000 estimated value: [317.23926] diferencia: [0.99944344]\n",
            "60 label value: 299990 estimated value: [317.23926] diferencia: [0.9989425]\n",
            "61 label value: 698000 estimated value: [317.23926] diferencia: [0.9995455]\n",
            "62 label value: 285000 estimated value: [317.23926] diferencia: [0.99888688]\n",
            "63 label value: 390000 estimated value: [317.23926] diferencia: [0.99918657]\n",
            "64 label value: 799000 estimated value: [317.23926] diferencia: [0.99960295]\n",
            "65 label value: 819000 estimated value: [317.23926] diferencia: [0.99961265]\n",
            "66 label value: 665000 estimated value: [317.23926] diferencia: [0.99952295]\n",
            "67 label value: 425000 estimated value: [317.23926] diferencia: [0.99925355]\n",
            "68 label value: 320000 estimated value: [317.23926] diferencia: [0.99900863]\n",
            "69 label value: 205000 estimated value: [317.23926] diferencia: [0.99845249]\n",
            "70 label value: 389977 estimated value: [317.23926] diferencia: [0.99918652]\n",
            "71 label value: 998800 estimated value: [317.23926] diferencia: [0.99968238]\n",
            "72 label value: 269900 estimated value: [317.23926] diferencia: [0.9988246]\n",
            "73 label value: 499000 estimated value: [317.23926] diferencia: [0.99936425]\n",
            "74 label value: 969000 estimated value: [317.23926] diferencia: [0.99967261]\n",
            "75 label value: 505000 estimated value: [317.23926] diferencia: [0.9993718]\n",
            "76 label value: 555000 estimated value: [317.23926] diferencia: [0.9994284]\n",
            "77 label value: 799888 estimated value: [317.23926] diferencia: [0.9996034]\n",
            "78 label value: 649888 estimated value: [317.23926] diferencia: [0.99951186]\n",
            "79 label value: 899000 estimated value: [317.23926] diferencia: [0.99964712]\n",
            "80 label value: 380000 estimated value: [317.23926] diferencia: [0.99916516]\n",
            "81 label value: 900000 estimated value: [317.23926] diferencia: [0.99964751]\n",
            "82 label value: 299000 estimated value: [317.23926] diferencia: [0.998939]\n",
            "83 label value: 599000 estimated value: [317.23926] diferencia: [0.99947039]\n",
            "84 label value: 1258888 estimated value: [317.23926] diferencia: [0.999748]\n",
            "85 label value: 750000 estimated value: [317.23926] diferencia: [0.99957701]\n",
            "86 label value: 649900 estimated value: [317.23926] diferencia: [0.99951186]\n",
            "87 label value: 505000 estimated value: [317.23926] diferencia: [0.9993718]\n",
            "88 label value: 315000 estimated value: [317.23926] diferencia: [0.99899289]\n",
            "89 label value: 250000 estimated value: [317.23926] diferencia: [0.99873104]\n",
            "90 label value: 565000 estimated value: [317.23926] diferencia: [0.99943851]\n",
            "91 label value: 629950 estimated value: [317.23926] diferencia: [0.99949641]\n",
            "92 label value: 1190000 estimated value: [317.23926] diferencia: [0.99973341]\n",
            "93 label value: 285000 estimated value: [317.23926] diferencia: [0.99888688]\n",
            "94 label value: 550000 estimated value: [317.23926] diferencia: [0.9994232]\n",
            "95 label value: 720000 estimated value: [317.23926] diferencia: [0.99955939]\n",
            "96 label value: 739000 estimated value: [317.23926] diferencia: [0.99957072]\n",
            "97 label value: 319900 estimated value: [317.23926] diferencia: [0.99900832]\n",
            "98 label value: 678900 estimated value: [317.23926] diferencia: [0.99953272]\n",
            "99 label value: 698000 estimated value: [317.23926] diferencia: [0.9995455]\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 100):\n",
        "    print (i ,\"label value:\", y_test[i], \"estimated value:\", y_predt1[i], \"diferencia:\", abs(y_test[i] - y_predt1[i])/y_test[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 2s 4ms/step - loss: 358191529984.0000 - mae: 468187.6250 - val_loss: 119583277056.0000 - val_mae: 241567.5469\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 99834732544.0000 - mae: 229698.0000 - val_loss: 100207542272.0000 - val_mae: 227014.7188\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 91291459584.0000 - mae: 221011.9062 - val_loss: 94252261376.0000 - val_mae: 222649.8125\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 88517083136.0000 - mae: 218523.4062 - val_loss: 90661945344.0000 - val_mae: 217648.1094\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 87077773312.0000 - mae: 216736.8281 - val_loss: 88728920064.0000 - val_mae: 215773.0625\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 86666764288.0000 - mae: 216781.2969 - val_loss: 87798841344.0000 - val_mae: 215915.8125\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85652201472.0000 - mae: 215417.8125 - val_loss: 87322787840.0000 - val_mae: 216919.8281\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85611986944.0000 - mae: 215199.5156 - val_loss: 90375454720.0000 - val_mae: 225617.3594\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 85250899968.0000 - mae: 215210.3594 - val_loss: 86702718976.0000 - val_mae: 214306.4688\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85517025280.0000 - mae: 215412.4062 - val_loss: 86350069760.0000 - val_mae: 214958.1094\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85196709888.0000 - mae: 214678.4531 - val_loss: 87424221184.0000 - val_mae: 220162.8438\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84945027072.0000 - mae: 214528.2500 - val_loss: 86202679296.0000 - val_mae: 213690.5781\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84992098304.0000 - mae: 214186.3125 - val_loss: 86056673280.0000 - val_mae: 216983.4375\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84640514048.0000 - mae: 214760.3281 - val_loss: 89065234432.0000 - val_mae: 223686.5156\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84588453888.0000 - mae: 214400.8906 - val_loss: 85788229632.0000 - val_mae: 212695.4219\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 84376772608.0000 - mae: 213681.7344 - val_loss: 85521530880.0000 - val_mae: 212021.3750\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 1s 5ms/step - loss: 84434370560.0000 - mae: 213440.1406 - val_loss: 85433278464.0000 - val_mae: 213174.4219\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: 84319502336.0000 - mae: 213246.7656 - val_loss: 85936046080.0000 - val_mae: 215498.7031\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84176535552.0000 - mae: 212879.2188 - val_loss: 85937012736.0000 - val_mae: 213786.1719\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84153860096.0000 - mae: 213086.9531 - val_loss: 86433955840.0000 - val_mae: 215453.8594\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83932856320.0000 - mae: 212517.5625 - val_loss: 87689773056.0000 - val_mae: 219020.2500\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84172603392.0000 - mae: 212909.0469 - val_loss: 86000771072.0000 - val_mae: 213518.4219\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84356210688.0000 - mae: 213171.5000 - val_loss: 87273291776.0000 - val_mae: 217675.4062\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83760750592.0000 - mae: 212194.4219 - val_loss: 86641786880.0000 - val_mae: 214699.9062\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83496943616.0000 - mae: 211923.0625 - val_loss: 88290516992.0000 - val_mae: 219346.4531\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83624026112.0000 - mae: 212385.5625 - val_loss: 86041714688.0000 - val_mae: 211020.1094\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83615932416.0000 - mae: 211713.0156 - val_loss: 87033561088.0000 - val_mae: 215036.2188\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83551789056.0000 - mae: 212075.3125 - val_loss: 86591750144.0000 - val_mae: 211453.9375\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83617734656.0000 - mae: 211859.3125 - val_loss: 88510095360.0000 - val_mae: 218903.3125\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83645784064.0000 - mae: 212227.8906 - val_loss: 89015181312.0000 - val_mae: 218735.6719\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83299491840.0000 - mae: 211709.6406 - val_loss: 87293853696.0000 - val_mae: 214386.1719\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83809951744.0000 - mae: 211978.5000 - val_loss: 86779584512.0000 - val_mae: 211980.0312\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84004716544.0000 - mae: 212115.2969 - val_loss: 87358357504.0000 - val_mae: 214709.3750\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83445374976.0000 - mae: 211796.0938 - val_loss: 89606029312.0000 - val_mae: 220376.3281\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83171442688.0000 - mae: 211429.4219 - val_loss: 87366303744.0000 - val_mae: 214485.5781\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83933077504.0000 - mae: 212244.3281 - val_loss: 87191855104.0000 - val_mae: 210584.3750\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83644792832.0000 - mae: 212028.1094 - val_loss: 87154384896.0000 - val_mae: 212964.3750\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 83150667776.0000 - mae: 211642.4531 - val_loss: 88061861888.0000 - val_mae: 215732.8125\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 83492782080.0000 - mae: 211955.2656 - val_loss: 87776174080.0000 - val_mae: 211289.1719\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 83189800960.0000 - mae: 211426.9062 - val_loss: 87041302528.0000 - val_mae: 210451.4219\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 83169771520.0000 - mae: 211251.0312 - val_loss: 87852326912.0000 - val_mae: 210218.7344\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 83065520128.0000 - mae: 210874.3438 - val_loss: 88793112576.0000 - val_mae: 216249.8906\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 83565092864.0000 - mae: 211872.8438 - val_loss: 87703347200.0000 - val_mae: 215002.4062\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: 83194388480.0000 - mae: 211173.6562 - val_loss: 88257060864.0000 - val_mae: 216487.0312\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 83240984576.0000 - mae: 211320.6719 - val_loss: 87623344128.0000 - val_mae: 214279.8594\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 83183714304.0000 - mae: 211311.8125 - val_loss: 86774792192.0000 - val_mae: 210630.5469\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 82919907328.0000 - mae: 210779.3281 - val_loss: 88720556032.0000 - val_mae: 218334.8438\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 82903957504.0000 - mae: 211282.8125 - val_loss: 87530160128.0000 - val_mae: 213517.3750\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83109273600.0000 - mae: 211399.4531 - val_loss: 87956733952.0000 - val_mae: 214643.0625\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83104251904.0000 - mae: 210959.0156 - val_loss: 86913441792.0000 - val_mae: 211553.0312\n"
          ]
        }
      ],
      "source": [
        "# Cambio 2: aumento del número de layers\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(64, activation='relu'))\n",
        "model2.add(Dense(32, activation='relu'))\n",
        "model2.add(Dense(1, activation='linear'))\n",
        "\n",
        "# añadimos el optimizador y la función de pérdida:\n",
        "model2.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# fiteamos el modelo:\n",
        "history = model2.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 1ms/step - loss: 89004089344.0000 - mae: 220271.1094\n",
            "Mean Absolute Error on Test Set: 220271.109375\n",
            "Mean Squared Error on Test Set: 89004089344.0\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "R^2 Score on Validation Set: 0.32136862240316444\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "R^2 Score on Test Set: 0.38244721209358834\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos:\n",
        "loss2, mae2 = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Absolute Error on Test Set: {mae2}')\n",
        "print(f'Mean Squared Error on Test Set: {loss2}')\n",
        "\n",
        "# No podemos usar accuracy_score, pero podemos usar:\n",
        "y_predv2 = model2.predict(X_val)\n",
        "r2_21 = r2_score(y_val, y_predv2)\n",
        "print(f'R^2 Score on Validation Set: {r2_21}')\n",
        "\n",
        "y_predt2 = model2.predict(X_test)\n",
        "r2_22 = r2_score(y_test, y_predt2)\n",
        "print(f'R^2 Score on Test Set: {r2_22}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 label value: 699000 estimated value: [690106.1] diferencia: [8893.875]\n",
            "2 label value: 599000 estimated value: [570068.44] diferencia: [28931.5625]\n",
            "3 label value: 1325000 estimated value: [1051464.] diferencia: [273536.]\n",
            "4 label value: 325000 estimated value: [531057.7] diferencia: [206057.6875]\n",
            "5 label value: 1639000 estimated value: [1738998.] diferencia: [99998.]\n",
            "6 label value: 1475000 estimated value: [803867.44] diferencia: [671132.5625]\n",
            "7 label value: 409000 estimated value: [400819.2] diferencia: [8180.8125]\n",
            "8 label value: 1795000 estimated value: [775192.7] diferencia: [1019807.3125]\n",
            "9 label value: 625000 estimated value: [551920.4] diferencia: [73079.625]\n",
            "10 label value: 249000 estimated value: [391526.4] diferencia: [142526.40625]\n",
            "11 label value: 980000 estimated value: [544333.4] diferencia: [435666.625]\n",
            "12 label value: 399000 estimated value: [466747.9] diferencia: [67747.90625]\n",
            "13 label value: 575500 estimated value: [675836.6] diferencia: [100336.625]\n",
            "14 label value: 598888 estimated value: [703115.4] diferencia: [104227.375]\n",
            "15 label value: 731414 estimated value: [561775.25] diferencia: [169638.75]\n",
            "16 label value: 315000 estimated value: [565415.9] diferencia: [250415.875]\n",
            "17 label value: 615000 estimated value: [1130529.8] diferencia: [515529.75]\n",
            "18 label value: 618000 estimated value: [710221.9] diferencia: [92221.875]\n",
            "19 label value: 305000 estimated value: [440847.3] diferencia: [135847.3125]\n",
            "20 label value: 744000 estimated value: [431784.9] diferencia: [312215.09375]\n",
            "21 label value: 349750 estimated value: [523718.22] diferencia: [173968.21875]\n",
            "22 label value: 699000 estimated value: [789977.7] diferencia: [90977.6875]\n",
            "23 label value: 750000 estimated value: [601016.6] diferencia: [148983.375]\n",
            "24 label value: 650000 estimated value: [482300.5] diferencia: [167699.5]\n",
            "25 label value: 1800000 estimated value: [817803.4] diferencia: [982196.625]\n",
            "26 label value: 569900 estimated value: [751392.6] diferencia: [181492.625]\n",
            "27 label value: 463000 estimated value: [504373.47] diferencia: [41373.46875]\n",
            "28 label value: 485000 estimated value: [707397.] diferencia: [222397.]\n",
            "29 label value: 789000 estimated value: [645959.25] diferencia: [143040.75]\n",
            "30 label value: 1350000 estimated value: [1761090.4] diferencia: [411090.375]\n",
            "31 label value: 1014900 estimated value: [477779.22] diferencia: [537120.78125]\n",
            "32 label value: 555000 estimated value: [904205.6] diferencia: [349205.625]\n",
            "33 label value: 579800 estimated value: [673995.3] diferencia: [94195.3125]\n",
            "34 label value: 218000 estimated value: [467301.56] diferencia: [249301.5625]\n",
            "35 label value: 599000 estimated value: [543894.5] diferencia: [55105.5]\n",
            "36 label value: 299000 estimated value: [421999.66] diferencia: [122999.65625]\n",
            "37 label value: 945000 estimated value: [650625.75] diferencia: [294374.25]\n",
            "38 label value: 899000 estimated value: [929623.25] diferencia: [30623.25]\n",
            "39 label value: 259000 estimated value: [463681.16] diferencia: [204681.15625]\n",
            "40 label value: 340000 estimated value: [683579.5] diferencia: [343579.5]\n",
            "41 label value: 888900 estimated value: [988283.44] diferencia: [99383.4375]\n",
            "42 label value: 554900 estimated value: [513789.72] diferencia: [41110.28125]\n",
            "43 label value: 1399900 estimated value: [684834.6] diferencia: [715065.375]\n",
            "44 label value: 298800 estimated value: [448061.1] diferencia: [149261.09375]\n",
            "45 label value: 249000 estimated value: [515763.47] diferencia: [266763.46875]\n",
            "46 label value: 535000 estimated value: [510377.6] diferencia: [24622.40625]\n",
            "47 label value: 929000 estimated value: [794650.25] diferencia: [134349.75]\n",
            "48 label value: 510990 estimated value: [632419.6] diferencia: [121429.625]\n",
            "49 label value: 779900 estimated value: [543616.8] diferencia: [236283.1875]\n",
            "50 label value: 799999 estimated value: [728117.75] diferencia: [71881.25]\n",
            "51 label value: 498000 estimated value: [457403.78] diferencia: [40596.21875]\n",
            "52 label value: 1050000 estimated value: [1436785.8] diferencia: [386785.75]\n",
            "53 label value: 699000 estimated value: [389792.7] diferencia: [309207.3125]\n",
            "54 label value: 850000 estimated value: [458500.66] diferencia: [391499.34375]\n",
            "55 label value: 375000 estimated value: [487250.53] diferencia: [112250.53125]\n",
            "56 label value: 899900 estimated value: [894711.06] diferencia: [5188.9375]\n",
            "57 label value: 515000 estimated value: [407306.] diferencia: [107694.]\n",
            "58 label value: 216500 estimated value: [412728.28] diferencia: [196228.28125]\n",
            "59 label value: 570000 estimated value: [908348.25] diferencia: [338348.25]\n",
            "60 label value: 299990 estimated value: [420888.9] diferencia: [120898.90625]\n",
            "61 label value: 698000 estimated value: [729204.6] diferencia: [31204.625]\n",
            "62 label value: 285000 estimated value: [368995.2] diferencia: [83995.1875]\n",
            "63 label value: 390000 estimated value: [601534.3] diferencia: [211534.3125]\n",
            "64 label value: 799000 estimated value: [783520.94] diferencia: [15479.0625]\n",
            "65 label value: 819000 estimated value: [704234.56] diferencia: [114765.4375]\n",
            "66 label value: 665000 estimated value: [505943.47] diferencia: [159056.53125]\n",
            "67 label value: 425000 estimated value: [870201.3] diferencia: [445201.3125]\n",
            "68 label value: 320000 estimated value: [503024.4] diferencia: [183024.40625]\n",
            "69 label value: 205000 estimated value: [453187.78] diferencia: [248187.78125]\n",
            "70 label value: 389977 estimated value: [613879.] diferencia: [223902.]\n",
            "71 label value: 998800 estimated value: [539699.75] diferencia: [459100.25]\n",
            "72 label value: 269900 estimated value: [621306.4] diferencia: [351406.375]\n",
            "73 label value: 499000 estimated value: [488013.72] diferencia: [10986.28125]\n",
            "74 label value: 969000 estimated value: [825313.4] diferencia: [143686.625]\n",
            "75 label value: 505000 estimated value: [446029.1] diferencia: [58970.90625]\n",
            "76 label value: 555000 estimated value: [904205.6] diferencia: [349205.625]\n",
            "77 label value: 799888 estimated value: [591223.1] diferencia: [208664.875]\n",
            "78 label value: 649888 estimated value: [649863.5] diferencia: [24.5]\n",
            "79 label value: 899000 estimated value: [749448.75] diferencia: [149551.25]\n",
            "80 label value: 380000 estimated value: [577802.3] diferencia: [197802.3125]\n",
            "81 label value: 900000 estimated value: [628483.56] diferencia: [271516.4375]\n",
            "82 label value: 299000 estimated value: [647462.75] diferencia: [348462.75]\n",
            "83 label value: 599000 estimated value: [595511.6] diferencia: [3488.375]\n",
            "84 label value: 1258888 estimated value: [640876.1] diferencia: [618011.875]\n",
            "85 label value: 750000 estimated value: [627984.25] diferencia: [122015.75]\n",
            "86 label value: 649900 estimated value: [704018.] diferencia: [54118.]\n",
            "87 label value: 505000 estimated value: [399593.25] diferencia: [105406.75]\n",
            "88 label value: 315000 estimated value: [440131.53] diferencia: [125131.53125]\n",
            "89 label value: 250000 estimated value: [514056.1] diferencia: [264056.09375]\n",
            "90 label value: 565000 estimated value: [520844.28] diferencia: [44155.71875]\n",
            "91 label value: 629950 estimated value: [546696.4] diferencia: [83253.625]\n",
            "92 label value: 1190000 estimated value: [1034699.] diferencia: [155301.]\n",
            "93 label value: 285000 estimated value: [403491.53] diferencia: [118491.53125]\n",
            "94 label value: 550000 estimated value: [538351.8] diferencia: [11648.1875]\n",
            "95 label value: 720000 estimated value: [786878.1] diferencia: [66878.125]\n",
            "96 label value: 739000 estimated value: [1121771.4] diferencia: [382771.375]\n",
            "97 label value: 319900 estimated value: [708213.06] diferencia: [388313.0625]\n",
            "98 label value: 678900 estimated value: [845738.5] diferencia: [166838.5]\n",
            "99 label value: 698000 estimated value: [729204.6] diferencia: [31204.625]\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 100):\n",
        "    print (i ,\"label value:\", y_test[i], \"estimated value:\", y_predt2[i], \"diferencia:\", abs(y_test[i] - y_predt2[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 549220974592.0000 - mae: 646376.8750 - val_loss: 320382009344.0000 - val_mae: 465124.9062\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 150498377728.0000 - mae: 282720.8750 - val_loss: 121268092928.0000 - val_mae: 238501.4688\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 102867460096.0000 - mae: 232562.2500 - val_loss: 106160324608.0000 - val_mae: 226987.5000\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 93934796800.0000 - mae: 223260.7500 - val_loss: 98155356160.0000 - val_mae: 222870.5469\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 90255491072.0000 - mae: 220324.7500 - val_loss: 94119051264.0000 - val_mae: 220764.8125\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 88243879936.0000 - mae: 218354.2344 - val_loss: 92697116672.0000 - val_mae: 222485.3438\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 87319330816.0000 - mae: 217644.5312 - val_loss: 89537740800.0000 - val_mae: 218179.3750\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 86540689408.0000 - mae: 216552.1250 - val_loss: 88381177856.0000 - val_mae: 216965.6250\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 86038855680.0000 - mae: 215912.5000 - val_loss: 88236433408.0000 - val_mae: 219663.4375\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85815549952.0000 - mae: 215788.1094 - val_loss: 87437713408.0000 - val_mae: 218832.5938\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85573910528.0000 - mae: 215607.5938 - val_loss: 86554673152.0000 - val_mae: 216906.3438\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85303148544.0000 - mae: 215472.0156 - val_loss: 86068756480.0000 - val_mae: 215331.4062\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 85203574784.0000 - mae: 215060.5000 - val_loss: 86156795904.0000 - val_mae: 216931.4062\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85080276992.0000 - mae: 214797.0312 - val_loss: 85675384832.0000 - val_mae: 216593.8125\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 85018779648.0000 - mae: 214775.4844 - val_loss: 85650210816.0000 - val_mae: 216863.1250\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84858634240.0000 - mae: 214707.7500 - val_loss: 85141880832.0000 - val_mae: 214584.6719\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84809768960.0000 - mae: 214212.3281 - val_loss: 86914793472.0000 - val_mae: 221764.4219\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84838957056.0000 - mae: 214826.2188 - val_loss: 84792705024.0000 - val_mae: 214766.4688\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84671283200.0000 - mae: 214097.2969 - val_loss: 86210297856.0000 - val_mae: 220648.1250\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84700274688.0000 - mae: 214699.9531 - val_loss: 84965523456.0000 - val_mae: 216281.0469\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84691763200.0000 - mae: 214130.7500 - val_loss: 84877000704.0000 - val_mae: 216410.8594\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84598784000.0000 - mae: 214198.4062 - val_loss: 85253144576.0000 - val_mae: 218061.9531\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84542480384.0000 - mae: 214189.2344 - val_loss: 85433335808.0000 - val_mae: 217911.7188\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84500643840.0000 - mae: 213924.5781 - val_loss: 85517582336.0000 - val_mae: 218795.0156\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84467933184.0000 - mae: 213891.8750 - val_loss: 85804154880.0000 - val_mae: 219285.4688\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84375355392.0000 - mae: 214099.5000 - val_loss: 84407246848.0000 - val_mae: 213485.7344\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84460920832.0000 - mae: 213593.5312 - val_loss: 85264261120.0000 - val_mae: 218000.4844\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84407615488.0000 - mae: 214054.6562 - val_loss: 84464582656.0000 - val_mae: 214921.9688\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84328792064.0000 - mae: 213676.5938 - val_loss: 85353054208.0000 - val_mae: 217863.1094\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84326178816.0000 - mae: 213558.9844 - val_loss: 84992106496.0000 - val_mae: 217360.8906\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84402446336.0000 - mae: 213828.9531 - val_loss: 84685135872.0000 - val_mae: 216291.7031\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84303282176.0000 - mae: 213583.9375 - val_loss: 84803428352.0000 - val_mae: 216618.4844\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84224065536.0000 - mae: 213490.0312 - val_loss: 84550819840.0000 - val_mae: 215693.3906\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84279255040.0000 - mae: 213795.7344 - val_loss: 84320395264.0000 - val_mae: 212618.9688\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84299931648.0000 - mae: 213403.9375 - val_loss: 84634968064.0000 - val_mae: 215261.8750\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84105084928.0000 - mae: 213358.4375 - val_loss: 84717600768.0000 - val_mae: 216288.1250\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84207149056.0000 - mae: 213644.7188 - val_loss: 84703109120.0000 - val_mae: 215450.8594\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84111597568.0000 - mae: 213077.1719 - val_loss: 84777025536.0000 - val_mae: 215901.8750\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84108525568.0000 - mae: 213202.8438 - val_loss: 84839931904.0000 - val_mae: 216266.2188\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84124336128.0000 - mae: 213071.9375 - val_loss: 84766048256.0000 - val_mae: 216710.0781\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84122664960.0000 - mae: 213264.7031 - val_loss: 85051416576.0000 - val_mae: 216786.6250\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84058341376.0000 - mae: 213194.7344 - val_loss: 84588650496.0000 - val_mae: 215199.7656\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84141531136.0000 - mae: 213130.6406 - val_loss: 84914036736.0000 - val_mae: 215669.2969\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 84053221376.0000 - mae: 212889.7812 - val_loss: 85121835008.0000 - val_mae: 216532.0625\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84008460288.0000 - mae: 212899.7031 - val_loss: 84873289728.0000 - val_mae: 216511.3594\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83957899264.0000 - mae: 212881.9062 - val_loss: 84699996160.0000 - val_mae: 215430.7656\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83983908864.0000 - mae: 212830.5625 - val_loss: 86186524672.0000 - val_mae: 219716.7344\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 83971203072.0000 - mae: 213009.0156 - val_loss: 85074632704.0000 - val_mae: 216606.9844\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: 84096106496.0000 - mae: 213097.3281 - val_loss: 84456701952.0000 - val_mae: 214126.7969\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: 83976126464.0000 - mae: 212851.7188 - val_loss: 84405460992.0000 - val_mae: 212878.4531\n"
          ]
        }
      ],
      "source": [
        "# Cambio 3: aumento del número de neuronas\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model3.add(Dense(300, activation='relu'))\n",
        "model3.add(Dense(300, activation='relu'))\n",
        "model3.add(Dense(1, activation='linear'))\n",
        "\n",
        "# añadimos el optimizador y la función de pérdida:\n",
        "model3.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
        "\n",
        "# fiteamos el modelo:\n",
        "history = model3.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/79 [..............................] - ETA: 2s - loss: 118082248704.0000 - mae: 241416.8281"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 1ms/step - loss: 89004089344.0000 - mae: 220271.1094\n",
            "Mean Absolute Error on Test Set: 220271.109375\n",
            "Mean Squared Error on Test Set: 89004089344.0\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "R^2 Score on Validation Set: 0.34095117416152776\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "R^2 Score on Test Set: 0.3729159953220321\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos:\n",
        "loss3, mae3= model.evaluate(X_test, y_test)\n",
        "print(f'Mean Absolute Error on Test Set: {mae3}')\n",
        "print(f'Mean Squared Error on Test Set: {loss3}')\n",
        "\n",
        "# No podemos usar accuracy_score, pero podemos usar:\n",
        "y_predv3 = model3.predict(X_val)\n",
        "r2_31 = r2_score(y_val, y_predv3)\n",
        "print(f'R^2 Score on Validation Set: {r2_31}')\n",
        "\n",
        "y_predt3 = model3.predict(X_test)\n",
        "r2_32 = r2_score(y_test, y_predt3)\n",
        "print(f'R^2 Score on Test Set: {r2_32}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 label value: 699000 estimated value: [682636.] diferencia: [16364.]\n",
            "2 label value: 599000 estimated value: [546635.44] diferencia: [52364.5625]\n",
            "3 label value: 1325000 estimated value: [1055661.4] diferencia: [269338.625]\n",
            "4 label value: 325000 estimated value: [462765.62] diferencia: [137765.625]\n",
            "5 label value: 1639000 estimated value: [1773315.6] diferencia: [134315.625]\n",
            "6 label value: 1475000 estimated value: [838949.75] diferencia: [636050.25]\n",
            "7 label value: 409000 estimated value: [398666.22] diferencia: [10333.78125]\n",
            "8 label value: 1795000 estimated value: [746305.5] diferencia: [1048694.5]\n",
            "9 label value: 625000 estimated value: [544975.75] diferencia: [80024.25]\n",
            "10 label value: 249000 estimated value: [473130.7] diferencia: [224130.6875]\n",
            "11 label value: 980000 estimated value: [588968.75] diferencia: [391031.25]\n",
            "12 label value: 399000 estimated value: [493509.16] diferencia: [94509.15625]\n",
            "13 label value: 575500 estimated value: [665403.7] diferencia: [89903.6875]\n",
            "14 label value: 598888 estimated value: [656885.] diferencia: [57997.]\n",
            "15 label value: 731414 estimated value: [559490.6] diferencia: [171923.375]\n",
            "16 label value: 315000 estimated value: [549270.75] diferencia: [234270.75]\n",
            "17 label value: 615000 estimated value: [1118103.4] diferencia: [503103.375]\n",
            "18 label value: 618000 estimated value: [684960.9] diferencia: [66960.875]\n",
            "19 label value: 305000 estimated value: [446127.47] diferencia: [141127.46875]\n",
            "20 label value: 744000 estimated value: [434191.3] diferencia: [309808.6875]\n",
            "21 label value: 349750 estimated value: [529993.75] diferencia: [180243.75]\n",
            "22 label value: 699000 estimated value: [816591.9] diferencia: [117591.875]\n",
            "23 label value: 750000 estimated value: [584818.75] diferencia: [165181.25]\n",
            "24 label value: 650000 estimated value: [488726.8] diferencia: [161273.1875]\n",
            "25 label value: 1800000 estimated value: [810691.9] diferencia: [989308.125]\n",
            "26 label value: 569900 estimated value: [741206.7] diferencia: [171306.6875]\n",
            "27 label value: 463000 estimated value: [442778.5] diferencia: [20221.5]\n",
            "28 label value: 485000 estimated value: [700598.7] diferencia: [215598.6875]\n",
            "29 label value: 789000 estimated value: [626645.9] diferencia: [162354.125]\n",
            "30 label value: 1350000 estimated value: [1767735.] diferencia: [417735.]\n",
            "31 label value: 1014900 estimated value: [524796.94] diferencia: [490103.0625]\n",
            "32 label value: 555000 estimated value: [909082.06] diferencia: [354082.0625]\n",
            "33 label value: 579800 estimated value: [680854.25] diferencia: [101054.25]\n",
            "34 label value: 218000 estimated value: [436111.] diferencia: [218111.]\n",
            "35 label value: 599000 estimated value: [533854.6] diferencia: [65145.375]\n",
            "36 label value: 299000 estimated value: [459815.7] diferencia: [160815.6875]\n",
            "37 label value: 945000 estimated value: [631179.25] diferencia: [313820.75]\n",
            "38 label value: 899000 estimated value: [925118.56] diferencia: [26118.5625]\n",
            "39 label value: 259000 estimated value: [494916.1] diferencia: [235916.09375]\n",
            "40 label value: 340000 estimated value: [639901.4] diferencia: [299901.375]\n",
            "41 label value: 888900 estimated value: [926483.25] diferencia: [37583.25]\n",
            "42 label value: 554900 estimated value: [513931.94] diferencia: [40968.0625]\n",
            "43 label value: 1399900 estimated value: [734697.2] diferencia: [665202.8125]\n",
            "44 label value: 298800 estimated value: [404177.28] diferencia: [105377.28125]\n",
            "45 label value: 249000 estimated value: [543397.1] diferencia: [294397.125]\n",
            "46 label value: 535000 estimated value: [508184.03] diferencia: [26815.96875]\n",
            "47 label value: 929000 estimated value: [826529.3] diferencia: [102470.6875]\n",
            "48 label value: 510990 estimated value: [618026.3] diferencia: [107036.3125]\n",
            "49 label value: 779900 estimated value: [540258.4] diferencia: [239641.625]\n",
            "50 label value: 799999 estimated value: [726334.9] diferencia: [73664.125]\n",
            "51 label value: 498000 estimated value: [484003.03] diferencia: [13996.96875]\n",
            "52 label value: 1050000 estimated value: [1433966.4] diferencia: [383966.375]\n",
            "53 label value: 699000 estimated value: [407289.94] diferencia: [291710.0625]\n",
            "54 label value: 850000 estimated value: [498508.28] diferencia: [351491.71875]\n",
            "55 label value: 375000 estimated value: [506619.94] diferencia: [131619.9375]\n",
            "56 label value: 899900 estimated value: [901985.4] diferencia: [2085.375]\n",
            "57 label value: 515000 estimated value: [428183.84] diferencia: [86816.15625]\n",
            "58 label value: 216500 estimated value: [464706.62] diferencia: [248206.625]\n",
            "59 label value: 570000 estimated value: [894020.6] diferencia: [324020.625]\n",
            "60 label value: 299990 estimated value: [444240.2] diferencia: [144250.1875]\n",
            "61 label value: 698000 estimated value: [701249.44] diferencia: [3249.4375]\n",
            "62 label value: 285000 estimated value: [433111.28] diferencia: [148111.28125]\n",
            "63 label value: 390000 estimated value: [609049.9] diferencia: [219049.875]\n",
            "64 label value: 799000 estimated value: [783497.75] diferencia: [15502.25]\n",
            "65 label value: 819000 estimated value: [701646.1] diferencia: [117353.875]\n",
            "66 label value: 665000 estimated value: [501762.94] diferencia: [163237.0625]\n",
            "67 label value: 425000 estimated value: [871859.56] diferencia: [446859.5625]\n",
            "68 label value: 320000 estimated value: [555219.1] diferencia: [235219.125]\n",
            "69 label value: 205000 estimated value: [469881.72] diferencia: [264881.71875]\n",
            "70 label value: 389977 estimated value: [583883.6] diferencia: [193906.625]\n",
            "71 label value: 998800 estimated value: [555636.9] diferencia: [443163.125]\n",
            "72 label value: 269900 estimated value: [612996.56] diferencia: [343096.5625]\n",
            "73 label value: 499000 estimated value: [477443.25] diferencia: [21556.75]\n",
            "74 label value: 969000 estimated value: [855935.4] diferencia: [113064.625]\n",
            "75 label value: 505000 estimated value: [423545.3] diferencia: [81454.6875]\n",
            "76 label value: 555000 estimated value: [909082.06] diferencia: [354082.0625]\n",
            "77 label value: 799888 estimated value: [585414.75] diferencia: [214473.25]\n",
            "78 label value: 649888 estimated value: [624124.75] diferencia: [25763.25]\n",
            "79 label value: 899000 estimated value: [794247.2] diferencia: [104752.8125]\n",
            "80 label value: 380000 estimated value: [564061.06] diferencia: [184061.0625]\n",
            "81 label value: 900000 estimated value: [522864.28] diferencia: [377135.71875]\n",
            "82 label value: 299000 estimated value: [657687.06] diferencia: [358687.0625]\n",
            "83 label value: 599000 estimated value: [593215.1] diferencia: [5784.875]\n",
            "84 label value: 1258888 estimated value: [628658.2] diferencia: [630229.8125]\n",
            "85 label value: 750000 estimated value: [616101.75] diferencia: [133898.25]\n",
            "86 label value: 649900 estimated value: [652404.1] diferencia: [2504.125]\n",
            "87 label value: 505000 estimated value: [441088.62] diferencia: [63911.375]\n",
            "88 label value: 315000 estimated value: [451325.44] diferencia: [136325.4375]\n",
            "89 label value: 250000 estimated value: [484119.8] diferencia: [234119.8125]\n",
            "90 label value: 565000 estimated value: [527679.7] diferencia: [37320.3125]\n",
            "91 label value: 629950 estimated value: [534211.5] diferencia: [95738.5]\n",
            "92 label value: 1190000 estimated value: [1096505.4] diferencia: [93494.625]\n",
            "93 label value: 285000 estimated value: [471503.16] diferencia: [186503.15625]\n",
            "94 label value: 550000 estimated value: [516277.84] diferencia: [33722.15625]\n",
            "95 label value: 720000 estimated value: [784123.75] diferencia: [64123.75]\n",
            "96 label value: 739000 estimated value: [1122625.6] diferencia: [383625.625]\n",
            "97 label value: 319900 estimated value: [709100.6] diferencia: [389200.625]\n",
            "98 label value: 678900 estimated value: [860058.25] diferencia: [181158.25]\n",
            "99 label value: 698000 estimated value: [701249.44] diferencia: [3249.4375]\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 100):\n",
        "    print (i ,\"label value:\", y_test[i], \"estimated value:\", y_predt3[i], \"diferencia:\", abs(y_test[i] - y_predt3[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "235/235 [==============================] - 1s 4ms/step - loss: nan - mae: 684978.7500 - val_loss: nan - val_mae: 680491.7500\n",
            "Epoch 2/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: nan - mae: 685468.5625 - val_loss: nan - val_mae: 681428.5000\n",
            "Epoch 3/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 687023.0625 - val_loss: nan - val_mae: 683802.8125\n",
            "Epoch 4/50\n",
            "235/235 [==============================] - 1s 2ms/step - loss: nan - mae: 690426.0625 - val_loss: nan - val_mae: 688555.6875\n",
            "Epoch 5/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 696690.4375 - val_loss: nan - val_mae: 696893.6875\n",
            "Epoch 6/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 707203.8750 - val_loss: nan - val_mae: 710434.5000\n",
            "Epoch 7/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 723970.6875 - val_loss: nan - val_mae: 731515.0625\n",
            "Epoch 8/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 749201.6250 - val_loss: nan - val_mae: 762756.5625\n",
            "Epoch 9/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 785997.1875 - val_loss: nan - val_mae: 807681.1875\n",
            "Epoch 10/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 838997.6250 - val_loss: nan - val_mae: 871726.1250\n",
            "Epoch 11/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 914123.9375 - val_loss: nan - val_mae: 963598.1250\n",
            "Epoch 12/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 1022925.1875 - val_loss: nan - val_mae: 1097036.3750\n",
            "Epoch 13/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 1182713.3750 - val_loss: nan - val_mae: 1295291.2500\n",
            "Epoch 14/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 1423374.6250 - val_loss: nan - val_mae: 1598411.7500\n",
            "Epoch 15/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 1797249.2500 - val_loss: nan - val_mae: 2076452.6250\n",
            "Epoch 16/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 2398540.5000 - val_loss: nan - val_mae: 2859053.7500\n",
            "Epoch 17/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 3400211.0000 - val_loss: nan - val_mae: 4180116.7500\n",
            "Epoch 18/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 5108649.5000 - val_loss: nan - val_mae: 6438319.5000\n",
            "Epoch 19/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 8025149.5000 - val_loss: nan - val_mae: 10273757.0000\n",
            "Epoch 20/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 12889356.0000 - val_loss: nan - val_mae: 16553981.0000\n",
            "Epoch 21/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 20646378.0000 - val_loss: nan - val_mae: 26318146.0000\n",
            "Epoch 22/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 32399776.0000 - val_loss: nan - val_mae: 40700136.0000\n",
            "Epoch 23/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 49305692.0000 - val_loss: nan - val_mae: 60882556.0000\n",
            "Epoch 24/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 72452920.0000 - val_loss: nan - val_mae: 87932696.0000\n",
            "Epoch 25/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 102856120.0000 - val_loss: nan - val_mae: 122727376.0000\n",
            "Epoch 26/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 141451312.0000 - val_loss: nan - val_mae: 166325920.0000\n",
            "Epoch 27/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 189154560.0000 - val_loss: nan - val_mae: 219467840.0000\n",
            "Epoch 28/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 246782080.0000 - val_loss: nan - val_mae: 283104544.0000\n",
            "Epoch 29/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 315018912.0000 - val_loss: nan - val_mae: 357773312.0000\n",
            "Epoch 30/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 394752288.0000 - val_loss: nan - val_mae: 444401248.0000\n",
            "Epoch 31/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 486837760.0000 - val_loss: nan - val_mae: 543837504.0000\n",
            "Epoch 32/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 592202496.0000 - val_loss: nan - val_mae: 657359040.0000\n",
            "Epoch 33/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 711744640.0000 - val_loss: nan - val_mae: 785314240.0000\n",
            "Epoch 34/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 846248000.0000 - val_loss: nan - val_mae: 928995712.0000\n",
            "Epoch 35/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 996610240.0000 - val_loss: nan - val_mae: 1088804480.0000\n",
            "Epoch 36/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 1163806464.0000 - val_loss: nan - val_mae: 1266208128.0000\n",
            "Epoch 37/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 1348542208.0000 - val_loss: nan - val_mae: 1461507072.0000\n",
            "Epoch 38/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 1551761280.0000 - val_loss: nan - val_mae: 1676123904.0000\n",
            "Epoch 39/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 1774537984.0000 - val_loss: nan - val_mae: 1910806528.0000\n",
            "Epoch 40/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 2017875328.0000 - val_loss: nan - val_mae: 2166337792.0000\n",
            "Epoch 41/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 2282695680.0000 - val_loss: nan - val_mae: 2444634624.0000\n",
            "Epoch 42/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 2570041600.0000 - val_loss: nan - val_mae: 2745211392.0000\n",
            "Epoch 43/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 2880857344.0000 - val_loss: nan - val_mae: 3070200320.0000\n",
            "Epoch 44/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 3216077568.0000 - val_loss: nan - val_mae: 3420649728.0000\n",
            "Epoch 45/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 3576873728.0000 - val_loss: nan - val_mae: 3797204736.0000\n",
            "Epoch 46/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 3964160512.0000 - val_loss: nan - val_mae: 4200265472.0000\n",
            "Epoch 47/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 4379297280.0000 - val_loss: nan - val_mae: 4632310784.0000\n",
            "Epoch 48/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 4823247872.0000 - val_loss: nan - val_mae: 5094393856.0000\n",
            "Epoch 49/50\n",
            "235/235 [==============================] - 0s 2ms/step - loss: nan - mae: 5297761280.0000 - val_loss: nan - val_mae: 5586793472.0000\n",
            "Epoch 50/50\n",
            "235/235 [==============================] - 1s 3ms/step - loss: nan - mae: 5803181568.0000 - val_loss: nan - val_mae: 6111356416.0000\n"
          ]
        }
      ],
      "source": [
        "# Cambio 4: cambio de la función de pérdida\n",
        "\n",
        "model4 = Sequential()\n",
        "model4.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
        "model4.add(Dense(64, activation='relu'))\n",
        "model4.add(Dense(64, activation='relu'))\n",
        "model4.add(Dense(1, activation='linear'))\n",
        "\n",
        "# añadimos el optimizador y la función de pérdida:\n",
        "model4.compile(optimizer='adam', loss='poisson', metrics=['mae'])\n",
        "\n",
        "# fiteamos el modelo:\n",
        "history = model4.fit(X_train, y_train, epochs=50, batch_size=32, validation_data=(X_val, y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " 1/79 [..............................] - ETA: 1s - loss: 118082248704.0000 - mae: 241416.8281"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "79/79 [==============================] - 0s 2ms/step - loss: 89004089344.0000 - mae: 220271.1094\n",
            "Mean Absolute Error on Test Set: 220271.109375\n",
            "Mean Squared Error on Test Set: 89004089344.0\n",
            "79/79 [==============================] - 1s 1ms/step\n",
            "R^2 Score on Validation Set: -354413011.99156505\n",
            "79/79 [==============================] - 0s 1ms/step\n",
            "R^2 Score on Test Set: 0.36795647997000736\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos:\n",
        "loss4, mae4 = model.evaluate(X_test, y_test)\n",
        "print(f'Mean Absolute Error on Test Set: {mae4}')\n",
        "print(f'Mean Squared Error on Test Set: {loss4}')\n",
        "\n",
        "# No podemos usar accuracy_score, pero podemos usar:\n",
        "y_predv4 = model4.predict(X_val)\n",
        "r2_41 = r2_score(y_val, y_predv4)\n",
        "print(f'R^2 Score on Validation Set: {r2_41}')\n",
        "\n",
        "y_predt4 = model.predict(X_test)\n",
        "r2_41 = r2_score(y_test, y_predt4)\n",
        "print(f'R^2 Score on Test Set: {r2_41}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1 label value: 699000 estimated value: [680685.6] diferencia: [18314.375]\n",
            "2 label value: 599000 estimated value: [526889.4] diferencia: [72110.625]\n",
            "3 label value: 1325000 estimated value: [1036050.] diferencia: [288950.]\n",
            "4 label value: 325000 estimated value: [399783.88] diferencia: [74783.875]\n",
            "5 label value: 1639000 estimated value: [1716848.9] diferencia: [77848.875]\n",
            "6 label value: 1475000 estimated value: [859520.5] diferencia: [615479.5]\n",
            "7 label value: 409000 estimated value: [363880.7] diferencia: [45119.3125]\n",
            "8 label value: 1795000 estimated value: [751137.8] diferencia: [1043862.1875]\n",
            "9 label value: 625000 estimated value: [538636.44] diferencia: [86363.5625]\n",
            "10 label value: 249000 estimated value: [479071.44] diferencia: [230071.4375]\n",
            "11 label value: 980000 estimated value: [584659.2] diferencia: [395340.8125]\n",
            "12 label value: 399000 estimated value: [476979.4] diferencia: [77979.40625]\n",
            "13 label value: 575500 estimated value: [658870.9] diferencia: [83370.875]\n",
            "14 label value: 598888 estimated value: [659463.75] diferencia: [60575.75]\n",
            "15 label value: 731414 estimated value: [554572.1] diferencia: [176841.875]\n",
            "16 label value: 315000 estimated value: [529963.1] diferencia: [214963.125]\n",
            "17 label value: 615000 estimated value: [1076088.1] diferencia: [461088.125]\n",
            "18 label value: 618000 estimated value: [664632.4] diferencia: [46632.375]\n",
            "19 label value: 305000 estimated value: [441792.44] diferencia: [136792.4375]\n",
            "20 label value: 744000 estimated value: [446768.62] diferencia: [297231.375]\n",
            "21 label value: 349750 estimated value: [527456.6] diferencia: [177706.625]\n",
            "22 label value: 699000 estimated value: [830887.44] diferencia: [131887.4375]\n",
            "23 label value: 750000 estimated value: [570148.5] diferencia: [179851.5]\n",
            "24 label value: 650000 estimated value: [476050.28] diferencia: [173949.71875]\n",
            "25 label value: 1800000 estimated value: [822654.44] diferencia: [977345.5625]\n",
            "26 label value: 569900 estimated value: [746383.75] diferencia: [176483.75]\n",
            "27 label value: 463000 estimated value: [384387.7] diferencia: [78612.3125]\n",
            "28 label value: 485000 estimated value: [707295.6] diferencia: [222295.625]\n",
            "29 label value: 789000 estimated value: [626998.] diferencia: [162002.]\n",
            "30 label value: 1350000 estimated value: [1742096.6] diferencia: [392096.625]\n",
            "31 label value: 1014900 estimated value: [527691.5] diferencia: [487208.5]\n",
            "32 label value: 555000 estimated value: [919986.5] diferencia: [364986.5]\n",
            "33 label value: 579800 estimated value: [660105.5] diferencia: [80305.5]\n",
            "34 label value: 218000 estimated value: [427918.] diferencia: [209918.]\n",
            "35 label value: 599000 estimated value: [532107.9] diferencia: [66892.125]\n",
            "36 label value: 299000 estimated value: [457041.75] diferencia: [158041.75]\n",
            "37 label value: 945000 estimated value: [622645.56] diferencia: [322354.4375]\n",
            "38 label value: 899000 estimated value: [937309.25] diferencia: [38309.25]\n",
            "39 label value: 259000 estimated value: [490338.8] diferencia: [231338.8125]\n",
            "40 label value: 340000 estimated value: [613891.9] diferencia: [273891.875]\n",
            "41 label value: 888900 estimated value: [926923.4] diferencia: [38023.375]\n",
            "42 label value: 554900 estimated value: [508379.56] diferencia: [46520.4375]\n",
            "43 label value: 1399900 estimated value: [746010.06] diferencia: [653889.9375]\n",
            "44 label value: 298800 estimated value: [384100.12] diferencia: [85300.125]\n",
            "45 label value: 249000 estimated value: [549354.56] diferencia: [300354.5625]\n",
            "46 label value: 535000 estimated value: [492489.6] diferencia: [42510.40625]\n",
            "47 label value: 929000 estimated value: [830809.4] diferencia: [98190.625]\n",
            "48 label value: 510990 estimated value: [610725.25] diferencia: [99735.25]\n",
            "49 label value: 779900 estimated value: [536327.4] diferencia: [243572.625]\n",
            "50 label value: 799999 estimated value: [714696.1] diferencia: [85302.875]\n",
            "51 label value: 498000 estimated value: [480731.] diferencia: [17269.]\n",
            "52 label value: 1050000 estimated value: [1365751.6] diferencia: [315751.625]\n",
            "53 label value: 699000 estimated value: [419003.] diferencia: [279997.]\n",
            "54 label value: 850000 estimated value: [492208.25] diferencia: [357791.75]\n",
            "55 label value: 375000 estimated value: [503105.94] diferencia: [128105.9375]\n",
            "56 label value: 899900 estimated value: [888018.1] diferencia: [11881.875]\n",
            "57 label value: 515000 estimated value: [421205.75] diferencia: [93794.25]\n",
            "58 label value: 216500 estimated value: [452553.44] diferencia: [236053.4375]\n",
            "59 label value: 570000 estimated value: [877793.06] diferencia: [307793.0625]\n",
            "60 label value: 299990 estimated value: [434681.06] diferencia: [134691.0625]\n",
            "61 label value: 698000 estimated value: [705999.3] diferencia: [7999.3125]\n",
            "62 label value: 285000 estimated value: [435025.] diferencia: [150025.]\n",
            "63 label value: 390000 estimated value: [600614.06] diferencia: [210614.0625]\n",
            "64 label value: 799000 estimated value: [792820.] diferencia: [6180.]\n",
            "65 label value: 819000 estimated value: [709713.8] diferencia: [109286.1875]\n",
            "66 label value: 665000 estimated value: [496619.53] diferencia: [168380.46875]\n",
            "67 label value: 425000 estimated value: [862307.5] diferencia: [437307.5]\n",
            "68 label value: 320000 estimated value: [561242.94] diferencia: [241242.9375]\n",
            "69 label value: 205000 estimated value: [465377.62] diferencia: [260377.625]\n",
            "70 label value: 389977 estimated value: [573552.4] diferencia: [183575.375]\n",
            "71 label value: 998800 estimated value: [556945.44] diferencia: [441854.5625]\n",
            "72 label value: 269900 estimated value: [604908.2] diferencia: [335008.1875]\n",
            "73 label value: 499000 estimated value: [463895.12] diferencia: [35104.875]\n",
            "74 label value: 969000 estimated value: [867614.25] diferencia: [101385.75]\n",
            "75 label value: 505000 estimated value: [383556.34] diferencia: [121443.65625]\n",
            "76 label value: 555000 estimated value: [919986.5] diferencia: [364986.5]\n",
            "77 label value: 799888 estimated value: [570150.3] diferencia: [229737.6875]\n",
            "78 label value: 649888 estimated value: [614575.6] diferencia: [35312.375]\n",
            "79 label value: 899000 estimated value: [800472.1] diferencia: [98527.875]\n",
            "80 label value: 380000 estimated value: [539342.25] diferencia: [159342.25]\n",
            "81 label value: 900000 estimated value: [474762.72] diferencia: [425237.28125]\n",
            "82 label value: 299000 estimated value: [621390.3] diferencia: [322390.3125]\n",
            "83 label value: 599000 estimated value: [587805.1] diferencia: [11194.875]\n",
            "84 label value: 1258888 estimated value: [625919.25] diferencia: [632968.75]\n",
            "85 label value: 750000 estimated value: [623242.6] diferencia: [126757.375]\n",
            "86 label value: 649900 estimated value: [646108.75] diferencia: [3791.25]\n",
            "87 label value: 505000 estimated value: [437460.44] diferencia: [67539.5625]\n",
            "88 label value: 315000 estimated value: [440212.5] diferencia: [125212.5]\n",
            "89 label value: 250000 estimated value: [475481.88] diferencia: [225481.875]\n",
            "90 label value: 565000 estimated value: [524687.3] diferencia: [40312.6875]\n",
            "91 label value: 629950 estimated value: [492483.84] diferencia: [137466.15625]\n",
            "92 label value: 1190000 estimated value: [1099570.] diferencia: [90430.]\n",
            "93 label value: 285000 estimated value: [472538.1] diferencia: [187538.09375]\n",
            "94 label value: 550000 estimated value: [506676.75] diferencia: [43323.25]\n",
            "95 label value: 720000 estimated value: [796270.94] diferencia: [76270.9375]\n",
            "96 label value: 739000 estimated value: [1088405.4] diferencia: [349405.375]\n",
            "97 label value: 319900 estimated value: [697573.56] diferencia: [377673.5625]\n",
            "98 label value: 678900 estimated value: [839497.75] diferencia: [160597.75]\n",
            "99 label value: 698000 estimated value: [705999.3] diferencia: [7999.3125]\n"
          ]
        }
      ],
      "source": [
        "for i in range(1, 100):\n",
        "    print (i ,\"label value:\", y_test[i], \"estimated value:\", y_predt4[i], \"diferencia:\", abs(y_test[i] - y_predt4[i]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V28KO-EDUwdz"
      },
      "source": [
        "* Basado en tus resultados, ¿cuáles son las características más importantes de un MLP para la predicción precisa en este conjunto de datos? ¿Cómo relacionas esto con la teoría aprendida?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nn0NvqU5Uwdz"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Casi nada cambia, solo el optimizador, y el cambio de la loss function provocó un cambio en el MSE. Aumentar el número de capas y de neuronas solo hizo el proceso más lento.\n",
        "\n",
        "Esto contrasta con la teoría respecto al número de capas y neuronas, fue cierto que aumentó el tiempo que demoraban en correr, pero fuera de eso no hubo mejorías u overfitting. En el caso del aumento de las neuronas de hecho, empeoró el rendimiento.\n",
        "\n",
        "\\\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iYw2Sx1TUwd0"
      },
      "source": [
        "* Describe los desafíos que encontraste al implementar y entrenar el MLP. ¿Cómo los superaste y qué aprendiste en el proceso? ¿en qué otros tipos de problemas crees que un MLP podría ser efectivo?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0dRndduUwd0"
      },
      "source": [
        "\\\\\n",
        "\n",
        "primero ocupé MLPClassifier(), el cual era similar a esta implementación, pero en una sola función, por tanto servía un tanto más como caja negra, aunque la explicación era fácil de encontrar. Sin embargo, me tiraba siempre el mismo y_predict para todo valor. Luego encontré esta implementación, y me costó entender el significado de cada cosa, pero chat gpt me ayudó. \n",
        "\n",
        "No logré mejorar más que esto mis predicciones con ningún cambio que realicé, ni bajando el número de neuronas, aumentando bastante más el número de capas, cambiando los epoch, etc.\n",
        "\n",
        "\n",
        "\n",
        "Me costó comprender porqué se implementaron algunas de las bibliotecas de la primera celda, pues muchas no las ocupé, como csr_matrix, que no sentí que fuera de importancia en lo absoluto.\n",
        "\n",
        "\n",
        "\n",
        "Un MLP también podría ser útil para buscar patrones en ventas de autos y estimación de su precio en un caso de regresión como este, recomendación de productos dado los gustos de una persona, convertir voz a texto o viceversa, etc.\n",
        "\n",
        "\\\\"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv_G6ngrUwd0"
      },
      "source": [
        "### Introducción y teoría de las CNN's"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V2YX1M70W-9n"
      },
      "source": [
        "* ¿Qué es una operación convolucional? ¿Qué es un *kernel*? Utiliza estos conceptos para explicar el rol de las capas convolucionales en una CNN."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CS5VZBTCXQ-t"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Esta es una operación invariante ante traslaciones, ya que captura features como cambios de tamaño, iluminación, o localización, que son invariantes al espacio.. Es decir, nos permitirá reconocer objetos en una foto independientemente de cómo este se vea.\n",
        "\n",
        "Al igual que un MLP, este posee una capa de entrada, capas ocultas y una de salida, con neuronas conectadas entre sí.\n",
        "\n",
        "Entonces, un CNN entonces es un tipo especializado de red neuronal capaz de procesar matemáticamente data como imágenes, utilizando kernels.\n",
        "\n",
        "Estos kernels mencionados son filtros especializados o pesos que se utilizan para convolucionar la data de entrada. Son algo así como una ventana que se va deslizando por sobre la matriz de entrada, aplicando operaciones matemáticas (producto punto entre el pixel de entrada y el del filtro en la misma posición y se van sumando todas las operaciones de esa ventana) para obtener en cada movimiento un solo valor de salida, generando así una matriz resultante de esas operaciones. Este proceso es lo que llamaremos una convolución, es el proceso visto en la última clase del curso.\n",
        "\n",
        "Existen kernels que suavizan la imagen, que detectan solo los bordes, que agregan contrastes y demás. Según lo que necesitemos, las que usaremos. Y la idea sería optimizar estos pesos de la mejor forma posible.\n",
        "\n",
        "Entonces, tendremos una matriz bidimensional que representa la imagen como data de entrada, la procesaremos mediante filtros o kernels, se aplicará una operación de convolución y se tendrá entonces un output de salida. Capas simples del inicio reconocerán features como colores y bordes, complejizándose cada vez más en cada capa hasta ir reconociendo lo que caracteriza a la imagen.\n",
        "\n",
        "Por ejemplo, una imagen a color entonces tendrá pixels 3D, probablemente en RGB. La imagen entonces se descompondrá no solo por colores, sino por las formas, y las partes escenciales que componen la estructura del objeto que se desea clasificar.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de: https://www.ibm.com/topics/convolutional-neural-networks \n",
        "https://courses.cs.washington.edu/courses/cse416/22su/lectures/10/lecture_10.pdf "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NG-L7hYhXRdx"
      },
      "source": [
        "* ¿Cuál es el rol de las funciones de activación? ¿Y de las capas de *Max Pooling*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIluL3gkXcWJ"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Estas son las llamadas \"Pooling layers\", que nos ayudan a bajar la dimensionalidad de la data, al bajar el número de parámetros.\n",
        "\n",
        "Esto es similar a las capas convolucionales que explicamos antes, que van aplicando un filtro a lo largo de la matriz de entrada, pero este no tiene los pesos mencionados antes, sino que se añaden funciones, siendo por tanto más simples de aplicar.\n",
        "\n",
        "Una de estas es el \"Max Pooling\", aquí se selecciona un ´pixel con el máximo valor para mandarlo al output de este filtro para esta zona. Entonces, se va generando una nueva matriz con los valores máximos representando cada zona. Otros podrían guardar el mínimo, media, mediana, o valores más bajos de los necesarios.\n",
        "\n",
        "Mucha información se termina perdiendo a través de estos, pero esto ayuda a la reducción en la complejidad, que mejora la eficiencia, limitando el riesgo de overfitting. Son de utilidad cuando las convoluciones no son suficientes para reducir la dimensionalidad de la data. Además, al igual que CNN, son invariantes a traslaciones. Max pooling sobre todo ha demostrado ser útil para guardar las características más importantes.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de: https://www.analyticsvidhya.com/blog/2021/05/convolutional-neural-networks-cnn/ \n",
        "https://courses.cs.washington.edu/courses/cse416/22su/lectures/10/lecture_10.pdf "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_Lbzpt6Xcym"
      },
      "source": [
        "* Quizás habrás notado que la mayoría de arquitecturas de CNN's utilizan una última capa conocida como *flatten layer*. ¿Cúal es su función? ¿Cuál es el rol de la función *softmax* en ella?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\\\\\n",
        "\n",
        "Al final del proceso de CNN suele estar este paso de \"aplanar\" el output de las capas de convolución, es decir los pixels se convierten de tensores (es decir, filtros en 4 dimensiones o multi-dimensional arrays) a vectores o arrays de una dimensión, de tal forma que el neural network puede leerlos. Este proceso se hace a través de la función Soft-max:\n",
        "\n",
        "Esta función se aplica a un conjunto de números y las convierte en probabilidades. Usualmente se usa en problemas de clasificación (sobretodo multiclase). Entonces, esta toma un vector de números reales y produce otro donde cada elemento en la salida es la exponencual del elemento que entró normalizado, de este modo, se suaviza y se convierte la data en probabilidades de 0 a 1, y al estar normalizados, sumarán en conjunto 1. En otras palabras, se reordena el mapa de información en una sola columna.\n",
        "\n",
        "Usualmente esta función es una generalización de la función logística que ya conocemos, solo que normalizada. Algo bueno es que el descenso del gradiente es fácil de aplicar aquí y funciona de forma bastante óptima.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de: https://arxiv.org/pdf/1412.5474.pdf\n",
        "https://www.quora.com/What-is-the-meaning-of-flattening-step-in-a-convolutional-neural-network\n",
        "https://www.codingninjas.com/studio/library/convolution-layer-padding-stride-and-pooling-in-cnn \n",
        "https://www.andreaperlato.com/aipost/cnn-and-softmax/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UgAad43XoE7"
      },
      "source": [
        "- ¿Cuáles son las ventajas y desventajas de las CNN's frente a las MLP's? ¿Para qué tipo de tareas suele ser útil utilizar CNN's?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUJOOc51XqjP"
      },
      "source": [
        "\\\\\n",
        "\n",
        "Los CNN tienen varias ventajas, como la compartición de parámetros, pues estos pesos de los kernels son iguales para toda la imagen, en vez de en las redes tradicionales, donde tenemos que ir buscando parámetro por parámetro, lo que demora bastante tiempo.\n",
        "\n",
        "Los CNN, como ya mencionamos, son invariantes ante traslaciones, algo que no siempre ocurre con su contraparte. Entonces, estos capturan features como bordes, texturas y formas. Es decir, su trabajo principal es capturar los features.\n",
        "\n",
        "Otra cosa a notar es que como mencionamos, el CNN alimenta al MLP, por tanto CNN sigue necesitando de MLP para funcionar a cabalidad, y a su vez, las CNN son más útiles cuando trabajamos con imágenes. Por otro lado, no son tan buenas para datos que no estén estructurados como estas matrices bidimensionales o datos no estructurados en general, ni tampoco para capturar features globales. Los MLP son más flexibles en estos sentidos.\n",
        "\n",
        "Por otro lado, los MLP son más propensos a sobreajustes, y no capturan tantas relaciones espaciales como un CNN.\n",
        "\n",
        "\\\\\n",
        "\n",
        "de: https://datascientest.com/es/convolutional-neural-network-es \n",
        "https://1library.co/article/comparativa-entre-comportamiento-de-mlp-y-cnn.z3e25x7q\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MRwswHqCXzrQ"
      },
      "source": [
        "### Creando y evaluando una CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNIli_avYa9T"
      },
      "source": [
        "\n",
        "Para entrenar nuestra red neuronal, utilizaremos la librería de [`TensorFlow`](https://www.tensorflow.org/api_docs/python/tf/all_symbols), podemos instalar esta librería mediante la línea `pip install tensorflow`.\n",
        "\n",
        "TensorFlow es una librería desarrollada por Google que nos permite construir, entrenar e implementar modelos de aprendizaje profundo en Python.\n",
        "\n",
        "Para esto, TensorFlow nos permite armar una red en forma de \"capas\", [en el siguiente link encontrarás un tutorial más en detalle de cómo crear un modelo de TensorFlow](https://towardsdatascience.com/building-our-first-neural-network-in-keras-bdc8abbc17f5). Deberemos introducir todas las capas de nuestra red dentro de un objeto `tf.keras.Sequential()`, que recibe de parámetro una lista con todos los elementos de nuestra red.\n",
        "\n",
        "<br>\n",
        "\n",
        "A continuación se enumeran los tres principales elementos que utilizaremos en nuestro modelo:\n",
        "- `tf.keras.Input(shape = a)`: La capa de entrada de la red, es la primera que recibe. Necesita de un parámetro `shape` que determinará la dimensionalidad del vector de entrada, esto será entregado en una tupla `a` (ej. `(5, 2)`).\n",
        "\n",
        "- `tf.keras.layers.Dense(units = b, activation = 'relu')`: Corresponde a una capa intermedia de la red del tipo *Fully Connected*, le entregaremos un parámetro `units` que determinará cuántas unidades ocultas (neuronas) tendrá la capa (y por tanto, el número de componentes en el vector de salida de la capa, en este caso `b`). Además, recibirá una función de activación para cada neurona, esta puede ser del tipo `relu`, `tanh`, `softmax` u otras, para más detalle sobre ellas visitar [el siguiente link](https://www.tensorflow.org/api_docs/python/tf/keras/activations). Recomendamos usar `relu` para capas intermedias.\n",
        "\n",
        "- `tf.keras.layers.Dense(units = c, activation = 'softmax')`: Similar a lo explicado anteriormente, corresponde a una capa densa de activación `softmax`. Esta corresponderá a la capa final del modelo, con `c` el número de elementos que deseamos que nuestro vector de salida tenga. El uso de una función softmax se debe a que esta nos permite llevar la salida de nuestra neurona a un conjunto de probabilidades normalizadas, desde el cual podemos calcular qué acción jugar. [En el siguiente link](https://deepai.org/machine-learning-glossary-and-terms/softmax-layer) se explica el funcionamiento de esta función en mayor detalle.\n",
        "\n",
        "<br>\n",
        "\n",
        "Un ejemplo de una red simple sería:\n",
        "```\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.Input(shape = a),\n",
        "    tf.keras.layers.Dense(b, activation = \"relu\"),\n",
        "    tf.keras.layers.Dense(c, activation = \"softmax\")\n",
        "])\n",
        "```\n",
        "\n",
        "Recuerda revisar las redes, tutoriales y tips del enunciado para ayudarte a confeccionar tu propia arquitectura. A continuación, importaremos algunas librerías que podrían ser útiles para tu desarrollo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "R1Mo3jemki9y"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.utils import load_img\n",
        "from tensorflow.keras.utils import img_to_array\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
        "\n",
        "\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical # -> no me funcionó bien\n",
        "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter)\n",
        "from dataclasses import dataclass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rboz01yNXqQ1"
      },
      "source": [
        "Primero, preprocesaremos los datos para poder entrenar nuestra red neuronal."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AbPIMK8r9LK"
      },
      "source": [
        "Descarga el dataset si no lo has hecho:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSg1NX5mrGoi",
        "outputId": "301bed1d-b58f-4923-9a4d-cb8f90bde933"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Access denied with the following error:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            " \tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses. \n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\t https://drive.google.com/uc?id=1078WtQHBTCe5amlDtfu3bgPbO9PFd31R \n",
            "\n",
            "\"unzip\" no se reconoce como un comando interno o externo,\n",
            "programa o archivo por lotes ejecutable.\n"
          ]
        }
      ],
      "source": [
        "!gdown https://drive.google.com/uc?id=1078WtQHBTCe5amlDtfu3bgPbO9PFd31R\n",
        "!unzip --qq multimodal_house_prices.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSj-VA0EsCb4"
      },
      "source": [
        "Para poder usar nuestros datos en CNN, necesitamos hacer un leve preprocesamiento de los mismos. Para ello, debemos asociar las imágenes de cada casa con su respectivo precio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "axUH1pD5r_pd"
      },
      "outputs": [],
      "source": [
        "base_path = 'multimodal_house_prices/'\n",
        "csv_file = os.path.join(base_path, 'data.csv')\n",
        "images_folder = os.path.join(base_path, 'images')\n",
        "\n",
        "data = pd.read_csv(csv_file)\n",
        "\n",
        "# Modificar cantidad de dataset y tamaño imágenes para ahorrar espacio en memoria.\n",
        "new_data = data.sample(frac=0.6)\n",
        "image_size = (156, 208)\n",
        "\n",
        "image_data = []\n",
        "prices = []\n",
        "\n",
        "for _, row in new_data.iterrows():\n",
        "    img_filename = os.path.join(images_folder, str(row['image_id']) + '.jpg')\n",
        "\n",
        "    img = load_img(img_filename, target_size=image_size)\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    img_array = img_array / 255.0 # vemos que la data ya está normalizada\n",
        "\n",
        "    image_data.append(img_array)\n",
        "    prices.append(row['price'])\n",
        "\n",
        "\n",
        "image_data = np.array(image_data)\n",
        "prices = np.array(prices)\n",
        "\n",
        "\n",
        "# Divide aquí tus datos\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_data, prices, test_size=0.2)\n",
        "\n",
        "# Recuerda borrar los numpy array para ahorrar memoria. -> Oki\n",
        "del image_data\n",
        "del prices\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6008, 156, 208, 3)\n",
            "(6008,)\n",
            "1802.3999999999999\n",
            "156 es el número de pixels \n",
            "\n",
            "[[[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]\n",
            "\n",
            " [[1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  ...\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]\n",
            "  [1. 1. 1.]]]\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "# Veamos cuántas imágenes tenemos en el entrenamiento para generar el test de validación:\n",
        "print(X_train.shape[0]*0.3)\n",
        "\n",
        "# Vemos también el tamaño de la imagen para luego saber qué input.shape tenemos:\n",
        "print(X_train.shape[1], \"es el número de pixels \\n\")\n",
        "\n",
        "print(X_train[100])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# no me funcionó la conversión y_train = to_categorical(y_train), así que usé otra transformación binaria:\n",
        "# de https://stackoverflow.com/questions/63407767/how-to-convert-a-vector-of-integers-into-a-matrix-of-binary-representation-with\n",
        "\n",
        "y_train = ((y_train.reshape(-1,1) & (2**np.arange(8))) != 0).astype(int)\n",
        "y_test = ((y_test.reshape(-1,1) & (2**np.arange(8))) != 0).astype(int)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "VRTy_25YclNY"
      },
      "outputs": [],
      "source": [
        "# de: https://stackoverflow.com/questions/63407767/how-to-convert-a-vector-of-integers-into-a-matrix-of-binary-representation-with\n",
        "\n",
        "# Basándonos en la ayudantía 12:\n",
        "\n",
        "# Tomamos las primeras 1500 imágenes, ya que eso es cerca del 30% del set de entrenamiento:\n",
        "X_valid = X_train[:1500]\n",
        "X_train = X_train[1500:]\n",
        "\n",
        "y_valid = y_train[:1500]\n",
        "y_train = y_train[1500:]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# https://www.projectpro.io/recipes/what-is-batch-normalization-keras\n",
        "# Here we are adding batch normalization after every layer which will reduce the internal covariate shift between the layers.\n",
        "# Se debe crear un modelo para nuestra red neuronal, añade cuantas capas ocultas desees, con cuantas neuronas desees\n",
        "\n",
        "# Nos basamos aquí de las ayudantías 12 y 13\n",
        "\n",
        "model_cnn = Sequential()\n",
        "\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu', input_shape = (156, 208, 3)))\n",
        "model_cnn.add(MaxPooling2D((2, 2)))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(Dropout(0.3))\n",
        "model_cnn.add(BatchNormalization())\n",
        "\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_cnn.add(MaxPooling2D((2, 2)))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(Dropout(0.3))\n",
        "model_cnn.add(BatchNormalization())\n",
        "\n",
        "model_cnn.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model_cnn.add(BatchNormalization())\n",
        "model_cnn.add(Dropout(0.3))\n",
        "model_cnn.add(BatchNormalization())\n",
        "\n",
        "model_cnn.add(Flatten())\n",
        "\n",
        "model_cnn.add(Dense(64, activation='relu'))\n",
        "model_cnn.add(Dense(1, activation=\"linear\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "sxyzyV12e189"
      },
      "outputs": [],
      "source": [
        "# Compila tu modelo de TensorFlow\n",
        "\n",
        "model_cnn.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "CS8fFkace6PL"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/15\n",
            "141/141 [==============================] - 215s 2s/step - loss: 23.4795 - mae: 1.2741 - val_loss: 44761.3945 - val_mae: 207.7862\n",
            "Epoch 2/15\n",
            "141/141 [==============================] - 210s 1s/step - loss: 15.1824 - mae: 0.8044 - val_loss: 647.9265 - val_mae: 12.6441\n",
            "Epoch 3/15\n",
            "141/141 [==============================] - 201s 1s/step - loss: 5.4746 - mae: 0.5089 - val_loss: 1.9902 - val_mae: 0.5033\n",
            "Epoch 4/15\n",
            "141/141 [==============================] - 192s 1s/step - loss: 10.5156 - mae: 0.6229 - val_loss: 2.7013 - val_mae: 0.5776\n",
            "Epoch 5/15\n",
            "141/141 [==============================] - 579s 4s/step - loss: 4.9493 - mae: 0.5429 - val_loss: 11.8570 - val_mae: 0.5420\n",
            "Epoch 6/15\n",
            "141/141 [==============================] - 249s 2s/step - loss: 0.9131 - mae: 0.4705 - val_loss: 1.7262 - val_mae: 0.4979\n",
            "Epoch 7/15\n",
            "141/141 [==============================] - 219s 2s/step - loss: 0.2565 - mae: 0.4712 - val_loss: 0.7222 - val_mae: 0.4906\n",
            "Epoch 8/15\n",
            "141/141 [==============================] - 196s 1s/step - loss: 0.2497 - mae: 0.4770 - val_loss: 0.3343 - val_mae: 0.4885\n",
            "Epoch 9/15\n",
            "141/141 [==============================] - 202s 1s/step - loss: 0.2416 - mae: 0.4773 - val_loss: 0.2937 - val_mae: 0.4827\n",
            "Epoch 10/15\n",
            "141/141 [==============================] - 196s 1s/step - loss: 0.2412 - mae: 0.4778 - val_loss: 0.2683 - val_mae: 0.4805\n",
            "Epoch 11/15\n",
            "141/141 [==============================] - 193s 1s/step - loss: 0.2402 - mae: 0.4776 - val_loss: 0.2666 - val_mae: 0.4897\n",
            "Epoch 12/15\n",
            "141/141 [==============================] - 829s 6s/step - loss: 0.2400 - mae: 0.4779 - val_loss: 0.2645 - val_mae: 0.4754\n",
            "Epoch 13/15\n",
            "141/141 [==============================] - 223s 2s/step - loss: 0.2412 - mae: 0.4780 - val_loss: 0.2566 - val_mae: 0.4841\n",
            "Epoch 14/15\n",
            "141/141 [==============================] - 222s 2s/step - loss: 0.2393 - mae: 0.4769 - val_loss: 0.2568 - val_mae: 0.4839\n",
            "Epoch 15/15\n",
            "141/141 [==============================] - 203s 1s/step - loss: 0.2388 - mae: 0.4764 - val_loss: 0.2577 - val_mae: 0.4772\n"
          ]
        }
      ],
      "source": [
        "# ===== COMPLETAR =====\n",
        "history = model_cnn.fit(X_train, y_train, epochs=15, validation_data=(X_valid, y_valid))\n",
        "\n",
        "# ====================="
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 14s 290ms/step - loss: 0.2577 - mae: 0.4772\n",
            "Mean Absolute Error on Test Set: 0.47719940543174744\n",
            "Mean Squared Error on Test Set: 0.25766873359680176\n",
            "47/47 [==============================] - 14s 296ms/step\n"
          ]
        }
      ],
      "source": [
        "# Evaluamos:\n",
        "loss, mae = model_cnn.evaluate(X_test, y_test)\n",
        "print(f'Mean Absolute Error on Test Set: {mae}')\n",
        "print(f'Mean Squared Error on Test Set: {loss}')\n",
        "\n",
        "ypred_cnn= model_cnn.predict(X_valid)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.19897857632326044\n",
            "0.45646205239675264\n",
            "0.767836410020079\n",
            "0.5786363173229425\n",
            "0.5425176108255982\n",
            "0.045181002953778145\n",
            "0.6737487935461104\n",
            "0.5745924752778732\n",
            "0.6449052542448044\n",
            "0.599617077938972\n",
            "0.3702638413953154\n",
            "0.1124342530965805\n",
            "0.5973226227567869\n",
            "0.45312838839448016\n",
            "11.55756426602602\n",
            "0.012690098662125436\n",
            "0.5046165755585484\n",
            "0.1721784613198704\n",
            "0.3675080392705767\n",
            "0.20776698738336563\n",
            "0.4691201194148997\n",
            "0.6419956829519041\n",
            "1.089262750554592\n",
            "0.33021031009654206\n",
            "11.164436411112547\n",
            "0.4571984656479048\n",
            "1.1330094980922611\n",
            "0.4785008678833644\n",
            "0.1554343154919999\n",
            "0.6306621169130648\n",
            "accuracy: 1.1995926547624307\n"
          ]
        }
      ],
      "source": [
        "#sacamos el accuracy de algunos de nuestros datos\n",
        "\n",
        "ypred_original = (ypred_cnn * (2**np.arange(8))).sum(axis=1) # volvemos los valores predichos a números\n",
        "y_test_original = (y_test * (2**np.arange(8))).sum(axis=1) # volvemos los valores predichos a números\n",
        "\n",
        "suma = 0\n",
        "# y para el accuracy:\n",
        "for i in range(0, 30):\n",
        "    suma += abs(y_test_original[i] - ypred_original[i])/y_test_original[i]\n",
        "    print(abs(y_test_original[i] - ypred_original[i])/y_test_original[i])\n",
        "\n",
        "print(\"accuracy:\", suma/ 30)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vemos que el error es bastante grande en algunos casos, pues el error promedio para estos 30 datos ya es mayor al 100%. Si bien algunos valores tienen un error bajo, muchos otros tienen uno mayor al 50%, y otros mayor al 1000%, lo cual es una estimación bastante mala. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# de la ayudantía 12:\n",
        "\n",
        "# Grafica tu función de pérdida.\n",
        "\n",
        "# Creamos la función\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss(history):\n",
        "    # Get the training loss from the history object\n",
        "    training_loss = history.history['loss']\n",
        "\n",
        "    # Get the validation loss from the history object, if available\n",
        "    validation_loss = history.history.get('val_loss', None)\n",
        "\n",
        "    # Get the number of epochs\n",
        "    epochs = range(1, len(training_loss) + 1)\n",
        "\n",
        "    # Plotting the training loss\n",
        "    plt.plot(epochs, training_loss, label='Training Loss')\n",
        "    \n",
        "    if validation_loss is not None:\n",
        "        # Plotting the validation loss if available\n",
        "        plt.plot(epochs, validation_loss, label='Validation Loss')\n",
        "\n",
        "    # Adding labels and title\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "\n",
        "    # Adding legend\n",
        "    plt.legend()\n",
        "\n",
        "    # Display the plot\n",
        "    plt.show()\n",
        "\n",
        "# Assuming 'history' is the history object returned by model.fit()\n",
        "plot_loss(history)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Esta función de pérdida evalúa qué tan bien se desempeña el modelo y cuánto se equivoca, es decir, mide la diferencia entre el valor real y el predecido. En este caso, vemos que mejora mucho con entre las primeras dos épocas, sin embargo, es difícil medir el desempeño más adelante, pues la gráfica tiene una escala muy grande. Aún así es de utilidad para ver el contraste en el aprendizaje, y ver cuántas épocas mínimas son necesarias para mejorar el algoritmo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lzW0zc5ZgDN"
      },
      "source": [
        "###Comparación de modelos\n",
        "A continuación, responde las siguientes preguntas relacionadas a comparar ambos tipos de redes neuronales:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXq1m9l4Ztql"
      },
      "source": [
        "* ¿Cuál de los modelos tiene un mejor *accuracy*?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulfQGNBkZy5x"
      },
      "source": [
        "Como podemos apreciar, el primero. Esto probablemente porque este posee información mucho más específica de muchos aspectos que aumentan el precio de la casa, mientras que el otro solo muestra una faceta."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AC8pTyIZzRh"
      },
      "source": [
        "* ¿Qué rangos de precios tienen un mejor rendimiento? ¿Y cuáles el peor? ¿Depende del modelo?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "para valores menores a 500 tenemos un accuracy promedio para cnn de:  inf\n",
            "para valores menores a 500 tenemos un accuracy promedio para mlp de:  40\n",
            " \n",
            " para valores menores a 1000 tenemos un accuracy promedio para cnn de:  1090\n",
            "para valores menores a 1000 tenemos un accuracy promedio para mlp de:  37\n",
            " \n",
            " para valores menores a 3000 tenemos un accuracy promedio para cnn de:  391\n",
            "para valores menores a 3000 tenemos un accuracy promedio para mlp de:  31\n",
            " \n",
            " para valores mayores a 3000 tenemos un accuracy promedio para cnn de:  49\n",
            "para valores mayores a 3000 tenemos un accuracy promedio para mlp de:  37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\kaori\\AppData\\Local\\Temp/ipykernel_26752/499551707.py:21: RuntimeWarning: divide by zero encountered in double_scalars\n",
            "  suma_cnn += 100*abs(y_test_original[i] - ypred_original[i])/y_test_original[i]\n"
          ]
        }
      ],
      "source": [
        "# haremos listas para guardar los rangos:\n",
        "\n",
        "bajo_500 = []\n",
        "bajo_1k = []\n",
        "bajo_3k = []\n",
        "sobre_3k = []\n",
        "\n",
        "for i in range(0, 1000):\n",
        "    if y_test_original[i] < 5:\n",
        "        bajo_500.append(i)  # vamos guardando los valores de los rangos\n",
        "    elif 5 <= y_test_original[i] < 10:\n",
        "        bajo_1k.append(i)\n",
        "    elif 10 <= y_test_original[i] < 30:\n",
        "        bajo_3k.append(i)\n",
        "    elif y_test_original[i] >= 30:\n",
        "        sobre_3k.append(i)\n",
        "\n",
        "suma_cnn = 0 # aquí calcularemos el accuracy de los modelos\n",
        "suma_mlp = 0 \n",
        "for i in bajo_500:\n",
        "    suma_cnn += 100*abs(y_test_original[i] - ypred_original[i])/y_test_original[i]\n",
        "    suma_mlp += 100*abs(y_test[i] - y_predt[i])/y_test[i]\n",
        "\n",
        "try:\n",
        "    valor = suma_cnn/len(bajo_500) # imprimimos el valor para CNN en el rango bajo 500\n",
        "    print(\"para valores menores a 500 tenemos un accuracy promedio para cnn de: \", valor)\n",
        "except ZeroDivisionError:\n",
        "    print(\"no tenemos valores aquí\")\n",
        "\n",
        "try:\n",
        "    valor = suma_mlp/len(bajo_500) # imprimimos el valor para MLP en el rango bajo 500\n",
        "    print(\"para valores menores a 500 tenemos un accuracy promedio para mlp de: \", int(valor))\n",
        "except ZeroDivisionError:\n",
        "    print(\"no tenemos valores aquí\")\n",
        "\n",
        "suma_cnn = 0\n",
        "suma_mlp = 0 \n",
        "for i in bajo_1k:\n",
        "    suma_cnn += 100*abs(y_test_original[i] - ypred_original[i])/y_test_original[i]\n",
        "    suma_mlp += 100*abs(y_test[i] - y_predt[i])/y_test[i]\n",
        "\n",
        "try:\n",
        "    valor = suma_cnn/len(bajo_1k) \n",
        "    print(\" \\n para valores menores a 1000 tenemos un accuracy promedio para cnn de: \", int(valor))\n",
        "except ZeroDivisionError:\n",
        "    print(\" \\n no tenemos valores aquí\")\n",
        "\n",
        "try:\n",
        "    valor = suma_mlp/len(bajo_1k)\n",
        "    print(\"para valores menores a 1000 tenemos un accuracy promedio para mlp de: \", int(valor))\n",
        "except ZeroDivisionError:\n",
        "    print(\"no tenemos valores aquí\")\n",
        "\n",
        "suma_cnn = 0\n",
        "suma_mlp = 0 \n",
        "for i in bajo_3k:\n",
        "    suma_cnn += 100*abs(y_test_original[i] - ypred_original[i])/y_test_original[i]\n",
        "    suma_mlp += 100*abs(y_test[i] - y_predt[i])/y_test[i]\n",
        "\n",
        "try:\n",
        "    valor = suma_cnn/len(bajo_3k) \n",
        "    print(\" \\n para valores menores a 3000 tenemos un accuracy promedio para cnn de: \", int(valor))\n",
        "except ZeroDivisionError:\n",
        "    print(\" \\n no tenemos valores aquí\")\n",
        "\n",
        "try:\n",
        "    valor = suma_mlp/len(bajo_3k)\n",
        "    print(\"para valores menores a 3000 tenemos un accuracy promedio para mlp de: \", int(valor))\n",
        "except ZeroDivisionError:\n",
        "    print(\"no tenemos valores aquí\")\n",
        "\n",
        "suma_cnn = 0\n",
        "suma_mlp = 0 \n",
        "for i in sobre_3k:\n",
        "    suma_cnn += 100*abs(y_test_original[i] - ypred_original[i])/y_test_original[i]\n",
        "    suma_mlp += 100*abs(y_test[i] - y_predt[i])/y_test[i]\n",
        "\n",
        "try:\n",
        "    valor = suma_cnn/len(sobre_3k) \n",
        "    print(\" \\n para valores mayores a 3000 tenemos un accuracy promedio para cnn de: \", int(valor))\n",
        "except ZeroDivisionError:\n",
        "    print(\" \\n no tenemos valores aquí\")\n",
        "\n",
        "try:\n",
        "    valor = suma_mlp/len(sobre_3k)\n",
        "    print(\"para valores mayores a 3000 tenemos un accuracy promedio para mlp de: \", int(valor))\n",
        "except ZeroDivisionError:\n",
        "    print(\"no tenemos valores aquí\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Hice rangos bajo 500 mil, bajo 1 millon, bajo 3 y sobre 3, y comparé para ambos modelos como se puede apreciar. Vemos que en todos los rangos tenemos valores bastante malos, pero por sobre todo para valores bajos es aún peor. CNN obtuvo el peor desempeño en todos los casos, sin embargo, al igual que para mlp, mejora para valores mayores, llegando a acercarse al final.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
